{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Thai Election Form Extractor - BigQuery + Google Drive Edition\n",
        "\n",
        "Extract structured data from election form PDFs stored in **Google Drive** using **BigQuery** to find files.\n",
        "\n",
        "**Key Advantages:**\n",
        "- üîç Query BigQuery to find PDF files\n",
        "- üìÅ Direct access to Google Drive files (no download needed!)\n",
        "- üöÄ Uses Gemini's External URLs file input method\n",
        "- ü§ñ Structured output with Pydantic schema validation\n",
        "\n",
        "**Reference:** [Gemini File Input Methods](https://ai.google.dev/gemini-api/docs/file-input-methods)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!source ../.env\n",
        "!pip install --upgrade pip\n",
        "!pip install -q google-cloud-bigquery google-genai pydantic pandas ddtrace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from typing import Optional\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from pydantic import BaseModel, Field\n",
        "from IPython.display import display, HTML\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Experiment configurations defined:\n",
            "   1. gemini-3-flash-preview         temp: 0.0   (thinking: LOW)\n",
            "   2. gemini-3-flash-preview         temp: 0.0   (thinking: HIGH)\n",
            "   3. gemini-3-pro-preview           temp: 0.0   (thinking: LOW)\n",
            "   4. gemini-3-pro-preview           temp: 0.0   (thinking: HIGH)\n",
            "   5. gemini-2.5-flash               temp: 0.0  \n",
            "   6. gemini-3-flash-preview         temp: 0.5   (thinking: LOW)\n",
            "   7. gemini-3-flash-preview         temp: 0.5   (thinking: HIGH)\n",
            "   8. gemini-3-pro-preview           temp: 0.5   (thinking: LOW)\n",
            "   9. gemini-3-pro-preview           temp: 0.5   (thinking: HIGH)\n",
            "   10. gemini-2.5-flash               temp: 0.5  \n"
          ]
        }
      ],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Optional, Literal\n",
        "\n",
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    \"\"\"Configuration for extraction experiments.\"\"\"\n",
        "    model: str\n",
        "    temperature: float = 0.0\n",
        "    max_tokens: int = 8192\n",
        "    thinking_mode: Optional[Literal[\"LOW\", \"HIGH\"]] = None\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        # Validate thinking_mode only for supported models\n",
        "        if self.thinking_mode:\n",
        "            if 'gemini-3' not in self.model.lower():\n",
        "                raise ValueError(\n",
        "                    f\"thinking_mode is only supported for gemini-3-pro-preview \"\n",
        "                    f\"and gemini-3-flash-preview. Got: {self.model}\"\n",
        "                )\n",
        "    \n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            'model': self.model,\n",
        "            'temperature': self.temperature,\n",
        "            'max_tokens': self.max_tokens,\n",
        "            'thinking_mode': self.thinking_mode,\n",
        "        }\n",
        "\n",
        "# Define experiment configurations\n",
        "EXPERIMENT_CONFIGS = [\n",
        "    # Temperature 0.0 (deterministic)\n",
        "    ExperimentConfig(model=\"gemini-3-flash-preview\", temperature=0.0, thinking_mode=\"LOW\"),\n",
        "    ExperimentConfig(model=\"gemini-3-flash-preview\", temperature=0.0, thinking_mode=\"HIGH\"),\n",
        "    ExperimentConfig(model=\"gemini-3-pro-preview\", temperature=0.0, thinking_mode=\"LOW\"),\n",
        "    ExperimentConfig(model=\"gemini-3-pro-preview\", temperature=0.0, thinking_mode=\"HIGH\"),\n",
        "    ExperimentConfig(model=\"gemini-2.5-flash\", temperature=0.0),  # No thinking mode\n",
        "    \n",
        "    # Temperature 0.5 (more creative)\n",
        "    ExperimentConfig(model=\"gemini-3-flash-preview\", temperature=0.5, thinking_mode=\"LOW\"),\n",
        "    ExperimentConfig(model=\"gemini-3-flash-preview\", temperature=0.5, thinking_mode=\"HIGH\"),\n",
        "    ExperimentConfig(model=\"gemini-3-pro-preview\", temperature=0.5, thinking_mode=\"LOW\"),\n",
        "    ExperimentConfig(model=\"gemini-3-pro-preview\", temperature=0.5, thinking_mode=\"HIGH\"),\n",
        "    ExperimentConfig(model=\"gemini-2.5-flash\", temperature=0.5),  # No thinking mode\n",
        "]\n",
        "\n",
        "print(\"‚úÖ Experiment configurations defined:\")\n",
        "for i, config in enumerate(EXPERIMENT_CONFIGS, 1):\n",
        "    thinking = f\" (thinking: {config.thinking_mode})\" if config.thinking_mode else \"\"\n",
        "    temp_str = f\"temp: {config.temperature}\"\n",
        "    print(f\"   {i}. {config.model:<30} {temp_str:<10} {thinking}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Environment variables set!\n",
            "‚úÖ Configuration\n",
            "   Project: datadog-ese-sandbox\n",
            "   API Key: ********************jezISbnw\n",
            "   Model: gemini-3-flash-preview\n",
            "   BigQuery Table: sourceinth.vote69_ect.raw_files\n"
          ]
        }
      ],
      "source": [
        "# Google Cloud Configuration\n",
        "\n",
        "# Set Gemini API Key (hidden input)\n",
        "if 'GEMINI_API_KEY' not in os.environ:\n",
        "    print(\"‚ö†Ô∏è  GEMINI_API_KEY not found in environment variables.\")\n",
        "    os.environ['GEMINI_API_KEY'] = 'AIzaSyC...' #@param {type:\"string\"}\n",
        "\n",
        "GEMINI_API_KEY = os.environ['GEMINI_API_KEY']\n",
        "\n",
        "# Set Google Cloud Project ID\n",
        "if 'GOOGLE_CLOUD_PROJECT' not in os.environ:\n",
        "    print(\"‚ö†Ô∏è  GOOGLE_CLOUD_PROJECT not found in environment variables.\")\n",
        "    os.environ['GOOGLE_CLOUD_PROJECT'] = 'YOUR_GCP_PROJECT_ID' #@param {type:\"string\"}\n",
        "\n",
        "GOOGLE_CLOUD_PROJECT = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "\n",
        "print(\"‚úÖ Environment variables set!\")\n",
        "\n",
        "# Model Configuration\n",
        "MODEL_NAME = \"gemini-3-flash-preview\"  # or \"gemini-3-pro-preview\", \"gemini-2.5-flash\"\n",
        "\n",
        "# BigQuery Configuration\n",
        "BQ_TABLE = \"sourceinth.vote69_ect.raw_files\"\n",
        "\n",
        "# Warn if API key is not set\n",
        "if not GEMINI_API_KEY:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: GEMINI_API_KEY is not set!\")\n",
        "    print(\"   Set it with: export GEMINI_API_KEY='your-key-here'\")\n",
        "    print(\"   Or create a .env file with GEMINI_API_KEY=your-key-here\")\n",
        "\n",
        "# Verify configuration\n",
        "print(f\"‚úÖ Configuration\")\n",
        "print(f\"   Project: {GOOGLE_CLOUD_PROJECT}\")\n",
        "print(f\"   API Key: {'*' * 20 + GEMINI_API_KEY[-8:] if GEMINI_API_KEY and len(GEMINI_API_KEY) > 8 else 'NOT SET ‚ö†Ô∏è'}\")\n",
        "print(f\"   Model: {MODEL_NAME}\")\n",
        "print(f\"   BigQuery Table: {BQ_TABLE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ddtrace.llmobs import LLMObs\n",
        "from ddtrace.llmobs.decorators import workflow, task\n",
        "from typing import Dict, Any, Optional, List\n",
        "\n",
        "ML_APP = \"gemini-ss5_18\" #@param {type:\"string\"}\n",
        "LLMOBS_PROJECT_NAME = \"vote-extraction-project\" #@param {type:\"string\"}\n",
        "\n",
        "LLMObs.enable(\n",
        "  ml_app=ML_APP,\n",
        "  api_key=os.environ['DD_API_KEY'],\n",
        "  app_key=os.environ['DD_APP_KEY'],\n",
        "  project_name=LLMOBS_PROJECT_NAME,\n",
        "  site=\"us3.datadoghq.com\",\n",
        "  agentless_enabled=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset loaded: 5 items\n",
            "   Dataset name: ss5_18_nuttee\n",
            "   Project: vote-extraction-project\n"
          ]
        }
      ],
      "source": [
        "# Pull dataset from LLMObs for experiments\n",
        "dataset = LLMObs.pull_dataset(\n",
        "    dataset_name=\"ss5_18_nuttee\",\n",
        "    project_name=LLMOBS_PROJECT_NAME,\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Dataset loaded: {len(dataset)} items\")\n",
        "print(f\"   Dataset name: ss5_18_nuttee\")\n",
        "print(f\"   Project: {LLMOBS_PROJECT_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Pydantic Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NumberTextPair(BaseModel):\n",
        "    \"\"\"Thai document number representation (both Arabic numeral and Thai text).\"\"\"\n",
        "    arabic: int = Field(..., description=\"Arabic numeral (e.g., 120)\")\n",
        "    thai_text: Optional[str] = Field(None, description=\"Thai text (e.g., '‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏£‡πâ‡∏≠‡∏¢‡∏¢‡∏µ‡πà‡∏™‡∏¥‡∏ö')\")\n",
        "\n",
        "\n",
        "class FormInfo(BaseModel):\n",
        "    \"\"\"Header information identifying the polling station.\"\"\"\n",
        "    form_type: Optional[str] = Field(None, description=\"Constituency or PartyList\")\n",
        "    set_number: Optional[str] = Field(None, description=\"Set number (‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà)\")  # NEW\n",
        "    date: Optional[str] = Field(None, description=\"Date of election\")\n",
        "    province: Optional[str] = Field(None, description=\"Province name\")\n",
        "    constituency_number: Optional[str] = Field(None, description=\"Constituency number\")\n",
        "    district: str = Field(..., description=\"District name\")\n",
        "    sub_district: Optional[str] = Field(None, description=\"Sub-district name\")\n",
        "    polling_station_number: str = Field(..., description=\"Polling station number\")\n",
        "    village_moo: Optional[str] = Field(None, description=\"Village number (‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà)\")  # NEW\n",
        "\n",
        "\n",
        "class VoterStatistics(BaseModel):\n",
        "    \"\"\"Voter statistics (Section 1).\"\"\"\n",
        "    eligible_voters: Optional[NumberTextPair] = Field(None, description=\"Total eligible voters\")\n",
        "    present_voters: Optional[NumberTextPair] = Field(None, description=\"Voters who showed up\")\n",
        "\n",
        "\n",
        "class BallotStatistics(BaseModel):\n",
        "    \"\"\"Ballot accounting statistics (Section 2).\"\"\"\n",
        "    ballots_allocated: Optional[NumberTextPair] = Field(None, description=\"Allocated ballots\")\n",
        "    ballots_used: Optional[NumberTextPair] = Field(None, description=\"Used ballots\")\n",
        "    good_ballots: Optional[NumberTextPair] = Field(None, description=\"Valid ballots\")\n",
        "    bad_ballots: Optional[NumberTextPair] = Field(None, description=\"Invalid ballots\")\n",
        "    no_vote_ballots: Optional[NumberTextPair] = Field(None, description=\"No vote ballots\")\n",
        "    ballots_remaining: Optional[NumberTextPair] = Field(None, description=\"Remaining ballots\")\n",
        "\n",
        "\n",
        "class VoteResult(BaseModel):\n",
        "    \"\"\"Individual vote result.\"\"\"\n",
        "    number: int = Field(..., description=\"Candidate/Party number\")\n",
        "    candidate_name: Optional[str] = Field(None, description=\"Candidate name (Constituency only)\")\n",
        "    party_name: Optional[str] = Field(None, description=\"Party name\")\n",
        "    vote_count: NumberTextPair = Field(..., description=\"Vote count (number + text)\")\n",
        "\n",
        "\n",
        "class Official(BaseModel):\n",
        "    \"\"\"Committee member/official.\"\"\"\n",
        "    name: str = Field(..., description=\"Full name of official\")\n",
        "    position: str = Field(..., description=\"Position/role (e.g., ‡∏õ‡∏£‡∏∞‡∏ò‡∏≤‡∏ô, ‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£)\")\n",
        "\n",
        "\n",
        "class ElectionFormData(BaseModel):\n",
        "    \"\"\"Complete election form extraction result.\"\"\"\n",
        "    form_info: FormInfo\n",
        "    voter_statistics: Optional[VoterStatistics] = None\n",
        "    ballot_statistics: Optional[BallotStatistics] = None\n",
        "    vote_results: list[VoteResult] = Field(default_factory=list)\n",
        "    total_votes_recorded: Optional[NumberTextPair] = Field(\n",
        "        None, \n",
        "        description=\"Total vote count from table footer\"\n",
        "    )  # NEW\n",
        "    officials: Optional[list[Official]] = Field(\n",
        "        None,\n",
        "        description=\"Committee members who signed the form\"\n",
        "    )  # NEW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluator Functions for LLMObs Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Evaluator functions defined:\n",
            "   - ballot_statistics\n",
            "   - voter_statistics\n",
            "   - total_votes\n",
            "\n",
            "Evaluators return float (0.0 to 1.0) for LLMObs experiments\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict, Any, List\n",
        "\n",
        "def evaluate_ballot_statistics(input_data, output_data, expected_output) -> float:\n",
        "    \"\"\"\n",
        "    Evaluate ballot statistics correctness.\n",
        "    \n",
        "    Returns float score (0.0 to 1.0) based on correctness of:\n",
        "    - ballots_allocated, ballots_used\n",
        "    - good_ballots, bad_ballots, no_vote_ballots\n",
        "    - ballots_remaining\n",
        "    - Validation: ballots_used = good + bad + no_vote\n",
        "    \n",
        "    Args:\n",
        "        input_data: File metadata (not used in evaluation)\n",
        "        output_data: Extracted report data (list of dicts)\n",
        "        expected_output: Expected values (dict with ballot_statistics)\n",
        "    \n",
        "    Returns:\n",
        "        float: Score from 0.0 to 1.0\n",
        "    \"\"\"\n",
        "    if not output_data or len(output_data) == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    report = output_data[0]  # Assume first report\n",
        "    ballot_stats = report.get('ballot_statistics', {})\n",
        "    expected_stats = expected_output.get('ballot_statistics', {})\n",
        "    \n",
        "    if not ballot_stats:\n",
        "        return 0.0\n",
        "    \n",
        "    # Helper to get arabic number\n",
        "    def get_val(obj):\n",
        "        if isinstance(obj, dict):\n",
        "            return obj.get('arabic', 0)\n",
        "        return obj or 0\n",
        "    \n",
        "    # Extract values\n",
        "    allocated = get_val(ballot_stats.get('ballots_allocated'))\n",
        "    used = get_val(ballot_stats.get('ballots_used'))\n",
        "    good = get_val(ballot_stats.get('good_ballots'))\n",
        "    bad = get_val(ballot_stats.get('bad_ballots'))\n",
        "    no_vote = get_val(ballot_stats.get('no_vote_ballots'))\n",
        "    remaining = get_val(ballot_stats.get('ballots_remaining'))\n",
        "    \n",
        "    # Expected values\n",
        "    exp_allocated = get_val(expected_stats.get('ballots_allocated'))\n",
        "    exp_used = get_val(expected_stats.get('ballots_used'))\n",
        "    exp_good = get_val(expected_stats.get('good_ballots'))\n",
        "    exp_bad = get_val(expected_stats.get('bad_ballots'))\n",
        "    exp_no_vote = get_val(expected_stats.get('no_vote_ballots'))\n",
        "    exp_remaining = get_val(expected_stats.get('ballots_remaining'))\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    checks = [\n",
        "        allocated == exp_allocated,\n",
        "        used == exp_used,\n",
        "        good == exp_good,\n",
        "        bad == exp_bad,\n",
        "        no_vote == exp_no_vote,\n",
        "        remaining == exp_remaining,\n",
        "    ]\n",
        "    \n",
        "    # Validation check\n",
        "    validation_pass = (used == good + bad + no_vote)\n",
        "    checks.append(validation_pass)\n",
        "    \n",
        "    correct = sum(checks)\n",
        "    total = len(checks)\n",
        "    score = correct / total\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "def evaluate_voter_statistics(input_data, output_data, expected_output) -> float:\n",
        "    \"\"\"\n",
        "    Evaluate voter statistics correctness.\n",
        "    \n",
        "    Returns float score (0.0 to 1.0) based on:\n",
        "    - eligible_voters\n",
        "    - present_voters\n",
        "    \n",
        "    Args:\n",
        "        input_data: File metadata (not used in evaluation)\n",
        "        output_data: Extracted report data (list of dicts)\n",
        "        expected_output: Expected values (dict with voter_statistics)\n",
        "    \n",
        "    Returns:\n",
        "        float: Score from 0.0 to 1.0\n",
        "    \"\"\"\n",
        "    if not output_data or len(output_data) == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    report = output_data[0]\n",
        "    voter_stats = report.get('voter_statistics', {})\n",
        "    expected_stats = expected_output.get('voter_statistics', {})\n",
        "    \n",
        "    if not voter_stats:\n",
        "        return 0.0\n",
        "    \n",
        "    def get_val(obj):\n",
        "        if isinstance(obj, dict):\n",
        "            return obj.get('arabic', 0)\n",
        "        return obj or 0\n",
        "    \n",
        "    eligible = get_val(voter_stats.get('eligible_voters'))\n",
        "    present = get_val(voter_stats.get('present_voters'))\n",
        "    \n",
        "    exp_eligible = get_val(expected_stats.get('eligible_voters'))\n",
        "    exp_present = get_val(expected_stats.get('present_voters'))\n",
        "    \n",
        "    checks = [\n",
        "        eligible == exp_eligible,\n",
        "        present == exp_present,\n",
        "    ]\n",
        "    \n",
        "    correct = sum(checks)\n",
        "    total = len(checks)\n",
        "    score = correct / total\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "def evaluate_total_votes(input_data, output_data, expected_output) -> float:\n",
        "    \"\"\"\n",
        "    Evaluate total votes correctness.\n",
        "    \n",
        "    Returns float score (0.0 to 1.0) based on:\n",
        "    - Sum of all vote counts matches total_votes_recorded\n",
        "    - Total matches expected value\n",
        "    \n",
        "    Args:\n",
        "        input_data: File metadata (not used in evaluation)\n",
        "        output_data: Extracted report data (list of dicts)\n",
        "        expected_output: Expected values (dict with total_votes_recorded)\n",
        "    \n",
        "    Returns:\n",
        "        float: Score from 0.0 to 1.0\n",
        "    \"\"\"\n",
        "    if not output_data or len(output_data) == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    report = output_data[0]\n",
        "    vote_results = report.get('vote_results', [])\n",
        "    total_recorded = report.get('total_votes_recorded')\n",
        "    \n",
        "    if not vote_results:\n",
        "        return 0.0\n",
        "    \n",
        "    def get_val(obj):\n",
        "        if isinstance(obj, dict):\n",
        "            return obj.get('arabic', 0)\n",
        "        return obj or 0\n",
        "    \n",
        "    # Calculate sum\n",
        "    calculated_total = sum(get_val(v.get('vote_count')) for v in vote_results)\n",
        "    recorded_total = get_val(total_recorded)\n",
        "    expected_total = get_val(expected_output.get('total_votes_recorded'))\n",
        "    \n",
        "    # Checks\n",
        "    internal_match = calculated_total == recorded_total\n",
        "    expected_match = recorded_total == expected_total\n",
        "    \n",
        "    checks = [internal_match, expected_match]\n",
        "    correct = sum(checks)\n",
        "    score = correct / len(checks)\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# Register evaluators for LLMObs\n",
        "EVALUATORS = {\n",
        "    \"ballot_statistics\": evaluate_ballot_statistics,\n",
        "    \"voter_statistics\": evaluate_voter_statistics,\n",
        "    \"total_votes\": evaluate_total_votes,\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Evaluator functions defined:\")\n",
        "for name in EVALUATORS.keys():\n",
        "    print(f\"   - {name}\")\n",
        "print(\"\\nEvaluators return float (0.0 to 1.0) for LLMObs experiments\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Experiments with Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Experiment functions defined\n",
            "\n",
            "Usage:\n",
            "  # Run single experiment:\n",
            "  experiment = run_single_experiment(EXPERIMENT_CONFIGS[0], dataset)\n",
            "\n",
            "  # Run all experiments:\n",
            "  experiments = run_all_experiments(dataset, EXPERIMENT_CONFIGS)\n"
          ]
        }
      ],
      "source": [
        "def run_single_experiment(\n",
        "    config: ExperimentConfig,\n",
        "    dataset,\n",
        "    experiment_name: str = None,\n",
        "    description: str = None,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Run a single experiment with LLMObs.experiment API.\n",
        "    \n",
        "    Args:\n",
        "        config: ExperimentConfig to test\n",
        "        dataset: LLMObs dataset\n",
        "        experiment_name: Optional experiment name\n",
        "        description: Optional description\n",
        "    \n",
        "    Returns:\n",
        "        Experiment object with results\n",
        "    \"\"\"\n",
        "    # Generate experiment name if not provided\n",
        "    if experiment_name is None:\n",
        "        thinking = f\"_thinking_{config.thinking_mode}\" if config.thinking_mode else \"\"\n",
        "        experiment_name = f\"{config.model.replace('.', '_').replace('-', '_')}{thinking}_temp{config.temperature}\"\n",
        "    \n",
        "    # Generate description\n",
        "    if description is None:\n",
        "        thinking_str = f\" with thinking mode {config.thinking_mode}\" if config.thinking_mode else \"\"\n",
        "        description = f\"Testing {config.model}{thinking_str} (temp={config.temperature})\"\n",
        "    \n",
        "    print(f\"\\nüöÄ Running experiment: {experiment_name}\")\n",
        "    print(f\"   Model: {config.model}\")\n",
        "    print(f\"   Temperature: {config.temperature}\")\n",
        "    print(f\"   Thinking mode: {config.thinking_mode or 'N/A'}\")\n",
        "    print(f\"   Dataset items: {len(list(dataset))}\")\n",
        "    print()\n",
        "    \n",
        "    # Create task wrapper that passes config\n",
        "    # Dataset items have structure: {'input_data': file_info, 'expected_output': ...}\n",
        "    def task_with_config(input_data, config) -> list[dict]:\n",
        "        \"\"\"Task function for LLMObs - must accept input_data and config.\"\"\"\n",
        "        return extraction_task(input_data, config)\n",
        "    \n",
        "    # Run experiment using LLMObs.experiment API\n",
        "    experiment = LLMObs.experiment(\n",
        "        name=experiment_name,\n",
        "        task=task_with_config,\n",
        "        dataset=dataset,\n",
        "        evaluators=list(EVALUATORS.values()),\n",
        "        description=description,\n",
        "        config=config.to_dict(),\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úÖ Experiment completed: {experiment_name}\")\n",
        "    print(f\"   Results available in Datadog LLMObs dashboard\")\n",
        "    \n",
        "    return experiment\n",
        "\n",
        "\n",
        "def run_all_experiments(\n",
        "    dataset,\n",
        "    configs: list[ExperimentConfig],\n",
        ") -> list:\n",
        "    \"\"\"\n",
        "    Run experiments for all configurations.\n",
        "    \n",
        "    Args:\n",
        "        dataset: LLMObs dataset\n",
        "        configs: List of ExperimentConfig to test\n",
        "    \n",
        "    Returns:\n",
        "        List of experiment objects\n",
        "    \"\"\"\n",
        "    experiments = []\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "    print(\"üöÄ Running Multiple Experiments\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nTotal configurations: {len(configs)}\")\n",
        "    print(f\"Dataset items: {len(list(dataset))}\")\n",
        "    print(f\"Total experiments: {len(configs)}\\n\")\n",
        "    \n",
        "    for i, config in enumerate(configs, 1):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Experiment {i}/{len(configs)}\")\n",
        "        print(f\"{'='*80}\")\n",
        "        \n",
        "        try:\n",
        "            experiment = run_single_experiment(config, dataset)\n",
        "            experiments.append(experiment)\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error running experiment {i}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    \n",
        "    print(f\"\\n\\n{'='*80}\")\n",
        "    print(f\"‚úÖ All experiments completed: {len(experiments)}/{len(configs)} successful\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"\\nüí° View results in Datadog LLMObs dashboard\")\n",
        "    print(f\"   Project: {LLMOBS_PROJECT_NAME}\")\n",
        "    print(f\"   ML App: {ML_APP}\")\n",
        "    \n",
        "    return experiments\n",
        "\n",
        "\n",
        "print(\"‚úÖ Experiment functions defined\")\n",
        "print(\"\\nUsage:\")\n",
        "print(\"  # Run single experiment:\")\n",
        "print(\"  experiment = run_single_experiment(EXPERIMENT_CONFIGS[0], dataset)\")\n",
        "print(\"\\n  # Run all experiments:\")\n",
        "print(\"  experiments = run_all_experiments(dataset, EXPERIMENT_CONFIGS)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Gemini Schema for Structured Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced schema for Gemini structured output with NumberTextPair\n",
        "ELECTION_DATA_SCHEMA = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"description\": \"List of election reports found in the PDF\",\n",
        "    \"items\": {\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"form_info\": {\n",
        "                \"type\": \"OBJECT\",\n",
        "                \"description\": \"Header information\",\n",
        "                \"properties\": {\n",
        "                    \"form_type\": {\n",
        "                        \"type\": \"STRING\",\n",
        "                        \"enum\": [\"Constituency\", \"PartyList\"],\n",
        "                        \"description\": \"Form type: Constituency (candidates) or PartyList (parties only)\"\n",
        "                    },\n",
        "                    \"set_number\": {\"type\": \"STRING\", \"description\": \"Set number (‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà)\"},\n",
        "                    \"date\": {\"type\": \"STRING\", \"description\": \"Date of election\"},\n",
        "                    \"province\": {\"type\": \"STRING\", \"description\": \"Province name\"},\n",
        "                    \"constituency_number\": {\"type\": \"STRING\", \"description\": \"Constituency number\"},\n",
        "                    \"district\": {\"type\": \"STRING\", \"description\": \"District name\"},\n",
        "                    \"sub_district\": {\"type\": \"STRING\", \"description\": \"Sub-district name\"},\n",
        "                    \"polling_station_number\": {\"type\": \"STRING\", \"description\": \"Polling station number\"},\n",
        "                    \"village_moo\": {\"type\": \"STRING\", \"description\": \"Village number (‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà)\"},\n",
        "                },\n",
        "                \"required\": [\"form_type\", \"province\", \"district\", \"polling_station_number\"],\n",
        "            },\n",
        "            \"voter_statistics\": {\n",
        "                \"type\": \"OBJECT\",\n",
        "                \"description\": \"Section 1: Voter statistics\",\n",
        "                \"properties\": {\n",
        "                    \"eligible_voters\": {\n",
        "                        \"type\": \"OBJECT\",\n",
        "                        \"description\": \"1.1 Total eligible voters\",\n",
        "                        \"properties\": {\n",
        "                            \"arabic\": {\"type\": \"INTEGER\"},\n",
        "                            \"thai_text\": {\"type\": \"STRING\"}\n",
        "                        }\n",
        "                    },\n",
        "                    \"present_voters\": {\n",
        "                        \"type\": \"OBJECT\",\n",
        "                        \"description\": \"1.2 Voters who showed up\",\n",
        "                        \"properties\": {\n",
        "                            \"arabic\": {\"type\": \"INTEGER\"},\n",
        "                            \"thai_text\": {\"type\": \"STRING\"}\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"ballot_statistics\": {\n",
        "                \"type\": \"OBJECT\",\n",
        "                \"description\": \"Section 2: Ballot accounting\",\n",
        "                \"properties\": {\n",
        "                    \"ballots_allocated\": {\n",
        "                        \"type\": \"OBJECT\",\n",
        "                        \"description\": \"2.1 Allocated ballots\",\n",
        "                        \"properties\": {\n",
        "                            \"arabic\": {\"type\": \"INTEGER\"},\n",
        "                            \"thai_text\": {\"type\": \"STRING\"}\n",
        "                        }\n",
        "                    },\n",
        "                    \"ballots_used\": {\n",
        "                        \"type\": \"OBJECT\",\n",
        "                        \"description\": \"2.2 Used ballots\",\n",
        "                        \"properties\": {\n",
        "                            \"arabic\": {\"type\": \"INTEGER\"},\n",
        "                            \"thai_text\": {\"type\": \"STRING\"}\n",
        "                        },\n",
        "                        \"required\": [\"arabic\"]\n",
        "                    },\n",
        "                    \"good_ballots\": {\n",
        "                        \"type\": \"OBJECT\",\n",
        "                        \"description\": \"2.2.1 Valid ballots\",\n",
        "                        \"properties\": {\n",
        "                            \"arabic\": {\"type\": \"INTEGER\"},\n",
        "                            \"thai_text\": {\"type\": \"STRING\"}\n",
        "                        },\n",
        "                        \"required\": [\"arabic\"]\n",
        "                    },\n",
        "                    \"bad_ballots\": {\n",
        "                        \"type\": \"OBJECT\",\n",
        "                        \"description\": \"2.2.2 Invalid ballots\",\n",
        "                        \"properties\": {\n",
        "                            \"arabic\": {\"type\": \"INTEGER\"},\n",
        "                            \"thai_text\": {\"type\": \"STRING\"}\n",
        "                        },\n",
        "                        \"required\": [\"arabic\"]\n",
        "                    },\n",
        "                    \"no_vote_ballots\": {\n",
        "                        \"type\": \"OBJECT\",\n",
        "                        \"description\": \"2.2.3 No vote ballots\",\n",
        "                        \"properties\": {\n",
        "                            \"arabic\": {\"type\": \"INTEGER\"},\n",
        "                            \"thai_text\": {\"type\": \"STRING\"}\n",
        "                        },\n",
        "                        \"required\": [\"arabic\"]\n",
        "                    },\n",
        "                    \"ballots_remaining\": {\n",
        "                        \"type\": \"OBJECT\",\n",
        "                        \"description\": \"2.3 Remaining ballots\",\n",
        "                        \"properties\": {\n",
        "                            \"arabic\": {\"type\": \"INTEGER\"},\n",
        "                            \"thai_text\": {\"type\": \"STRING\"}\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"vote_results\": {\n",
        "                \"type\": \"ARRAY\",\n",
        "                \"description\": \"Section 3: Vote counts for all candidates/parties\",\n",
        "                \"items\": {\n",
        "                    \"type\": \"OBJECT\",\n",
        "                    \"properties\": {\n",
        "                        \"number\": {\"type\": \"INTEGER\", \"description\": \"Candidate/Party number\"},\n",
        "                        \"candidate_name\": {\n",
        "                            \"type\": \"STRING\",\n",
        "                            \"description\": \"Candidate name (for Constituency forms only)\"\n",
        "                        },\n",
        "                        \"party_name\": {\"type\": \"STRING\", \"description\": \"Party name\"},\n",
        "                        \"vote_count\": {\n",
        "                            \"type\": \"OBJECT\",\n",
        "                            \"description\": \"Vote count (both number and Thai text)\",\n",
        "                            \"properties\": {\n",
        "                                \"arabic\": {\"type\": \"INTEGER\"},\n",
        "                                \"thai_text\": {\"type\": \"STRING\"}\n",
        "                            },\n",
        "                            \"required\": [\"arabic\"]\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"number\", \"vote_count\"]\n",
        "                },\n",
        "            },\n",
        "            \"total_votes_recorded\": {\n",
        "                \"type\": \"OBJECT\",\n",
        "                \"description\": \"Total vote count from bottom of table (for validation)\",\n",
        "                \"properties\": {\n",
        "                    \"arabic\": {\"type\": \"INTEGER\"},\n",
        "                    \"thai_text\": {\"type\": \"STRING\"}\n",
        "                }\n",
        "            },\n",
        "            \"officials\": {\n",
        "                \"type\": \"ARRAY\",\n",
        "                \"description\": \"Committee members who signed the form\",\n",
        "                \"items\": {\n",
        "                    \"type\": \"OBJECT\",\n",
        "                    \"properties\": {\n",
        "                        \"name\": {\"type\": \"STRING\", \"description\": \"Full name\"},\n",
        "                        \"position\": {\"type\": \"STRING\", \"description\": \"Position (‡∏õ‡∏£‡∏∞‡∏ò‡∏≤‡∏ô, ‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£, etc.)\"}\n",
        "                    },\n",
        "                    \"required\": [\"name\", \"position\"]\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"form_info\", \"vote_results\"],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initialize Clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ BigQuery client initialized\n",
            "‚úÖ Gemini client initialized (using API key)\n",
            "   Ready to use gemini-3-flash-preview\n"
          ]
        }
      ],
      "source": [
        "# Initialize BigQuery client\n",
        "bq_client = bigquery.Client(project=GOOGLE_CLOUD_PROJECT)\n",
        "print(\"‚úÖ BigQuery client initialized\")\n",
        "\n",
        "# Initialize Gemini client with API key\n",
        "if not GEMINI_API_KEY:\n",
        "    raise ValueError(\n",
        "        \"GEMINI_API_KEY is required! Set it with:\\n\"\n",
        "        \"  export GEMINI_API_KEY='your-key-here'\\n\"\n",
        "        \"  or create a .env file\"\n",
        "    )\n",
        "\n",
        "gemini_client = genai.Client(\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    vertexai=False,\n",
        ")\n",
        "print(\"‚úÖ Gemini client initialized (using API key)\")\n",
        "print(f\"   Ready to use {MODEL_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Query BigQuery for PDF Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Querying BigQuery...\n",
            "   Filters: mime_type = 'application/pdf' AND size >= 51200 AND size <= 52428800\n",
            "‚úÖ Found 10 file(s)\n",
            "   Size range: 50.0 KB - 50.4 KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>province_name</th>\n",
              "      <th>path</th>\n",
              "      <th>size_mb</th>\n",
              "      <th>file_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£</td>\n",
              "      <td>‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ó‡∏ï.‡πÇ‡∏û‡∏ò‡∏¥...</td>\n",
              "      <td>0.048851</td>\n",
              "      <td>1_j0DNaqCXIkEk0MK3y0J1eCN3hUOCXeF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£</td>\n",
              "      <td>‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ï‡∏≥‡∏ö‡∏•‡πÑ‡∏ú‡πà...</td>\n",
              "      <td>0.048915</td>\n",
              "      <td>1gDxp58u2W14uhdb6NpRDqxl1d7aa2WFy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£</td>\n",
              "      <td>‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ï‡∏≥‡∏ö‡∏•‡πÑ‡∏ú‡πà...</td>\n",
              "      <td>0.048917</td>\n",
              "      <td>1a5jF1Oyv3UEatBq1MT1ga8kS10uR19-c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£</td>\n",
              "      <td>‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ï‡∏≥‡∏ö‡∏•‡∏î‡∏á‡πÄ...</td>\n",
              "      <td>0.048927</td>\n",
              "      <td>1tzz6gMXk1n3pQtreQWMIU2xlkncg-g_r</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£</td>\n",
              "      <td>‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ó‡∏ï.‡πÇ‡∏û‡∏ò‡∏¥...</td>\n",
              "      <td>0.048993</td>\n",
              "      <td>1-MsML3nSXUrscvmzdZb7R4yTkZcuTc5m</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  province_name                                               path   size_mb  \\\n",
              "0        ‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£  ‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ó‡∏ï.‡πÇ‡∏û‡∏ò‡∏¥...  0.048851   \n",
              "1        ‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£  ‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ï‡∏≥‡∏ö‡∏•‡πÑ‡∏ú‡πà...  0.048915   \n",
              "2        ‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£  ‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ï‡∏≥‡∏ö‡∏•‡πÑ‡∏ú‡πà...  0.048917   \n",
              "3        ‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£  ‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ï‡∏≥‡∏ö‡∏•‡∏î‡∏á‡πÄ...  0.048927   \n",
              "4        ‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£  ‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ó‡∏ï.‡πÇ‡∏û‡∏ò‡∏¥...  0.048993   \n",
              "\n",
              "                             file_id  \n",
              "0  1_j0DNaqCXIkEk0MK3y0J1eCN3hUOCXeF  \n",
              "1  1gDxp58u2W14uhdb6NpRDqxl1d7aa2WFy  \n",
              "2  1a5jF1Oyv3UEatBq1MT1ga8kS10uR19-c  \n",
              "3  1tzz6gMXk1n3pQtreQWMIU2xlkncg-g_r  \n",
              "4  1-MsML3nSXUrscvmzdZb7R4yTkZcuTc5m  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "failed to send, dropping 2 traces to intake at http://datadog-agent:8126/v0.5/traces: client error (Connect) [1 skipped]\n"
          ]
        }
      ],
      "source": [
        "def query_pdf_files(\n",
        "    limit: int = 10,\n",
        "    province: Optional[str] = None,\n",
        "    min_size_kb: float = 50.0,\n",
        "    max_size_mb: Optional[float] = 50.0\n",
        ") -> list[dict]:\n",
        "    \"\"\"\n",
        "    Query BigQuery for PDF files.\n",
        "    \n",
        "    Args:\n",
        "        limit: Maximum number of files to return\n",
        "        province: Filter by province name (optional)\n",
        "        min_size_kb: Minimum file size in KB (default: 50 KB to exclude corrupted files)\n",
        "        max_size_mb: Maximum file size in MB (optional)\n",
        "    \n",
        "    Returns:\n",
        "        List of file metadata dicts\n",
        "    \"\"\"\n",
        "    # Build query\n",
        "    conditions = [\"mime_type = 'application/pdf'\"]\n",
        "    \n",
        "    # Add minimum size filter (exclude very small/corrupted files)\n",
        "    min_bytes = int(min_size_kb * 1024)\n",
        "    conditions.append(f\"size >= {min_bytes}\")\n",
        "    \n",
        "    if province:\n",
        "        conditions.append(f\"province_name = '{province}'\")\n",
        "    \n",
        "    if max_size_mb:\n",
        "        max_bytes = int(max_size_mb * 1024 * 1024)\n",
        "        conditions.append(f\"size <= {max_bytes}\")\n",
        "    \n",
        "    where_clause = \" AND \".join(conditions)\n",
        "    \n",
        "    query = f\"\"\"\n",
        "    SELECT \n",
        "        file_id, \n",
        "        path,\n",
        "        mime_type, \n",
        "        folder_id, \n",
        "        province_name,\n",
        "        size,\n",
        "        mod_time\n",
        "    FROM `{BQ_TABLE}`\n",
        "    WHERE {where_clause}\n",
        "    ORDER BY size ASC\n",
        "    LIMIT {limit}\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"üîç Querying BigQuery...\")\n",
        "    print(f\"   Filters: {where_clause}\")\n",
        "    \n",
        "    # Execute query\n",
        "    query_job = bq_client.query(query)\n",
        "    results = query_job.result()\n",
        "    \n",
        "    # Convert to list\n",
        "    files = []\n",
        "    for row in results:\n",
        "        files.append({\n",
        "            \"file_id\": row.file_id,\n",
        "            \"path\": row.path,\n",
        "            \"mime_type\": row.mime_type,\n",
        "            \"folder_id\": row.folder_id,\n",
        "            \"province_name\": row.province_name,\n",
        "            \"size\": row.size,\n",
        "            \"size_mb\": row.size / (1024 * 1024) if row.size else 0,\n",
        "            \"size_kb\": row.size / 1024 if row.size else 0,\n",
        "            \"mod_time\": row.mod_time,\n",
        "        })\n",
        "    \n",
        "    print(f\"‚úÖ Found {len(files)} file(s)\")\n",
        "    print(f\"   Size range: {files[0]['size_kb']:.1f} KB - {files[-1]['size_kb']:.1f} KB\" if files else \"\")\n",
        "    return files\n",
        "\n",
        "\n",
        "# Query for files (min 50 KB, max 50 MB)\n",
        "pdf_files = query_pdf_files(limit=10, min_size_kb=50.0, max_size_mb=50.0)\n",
        "\n",
        "# Display as DataFrame\n",
        "if pdf_files:\n",
        "    df = pd.DataFrame(pdf_files)\n",
        "    display(df[['province_name', 'path', 'size_mb', 'file_id']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Select Test File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ Selected Test File:\n",
            "================================================================================\n",
            "Province: ‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£\n",
            "Path: ‡πÄ‡∏Ç‡∏ï‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 3/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏ó‡∏ï.‡πÇ‡∏û‡∏ò‡∏¥‡πå‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡∏ä‡πâ‡∏≤‡∏á/‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 9/‡∏™‡∏™5‡∏ó‡∏±‡∏ö18 ‡∏ô_09.pdf\n",
            "File ID: 1_j0DNaqCXIkEk0MK3y0J1eCN3hUOCXeF\n",
            "Size: 0.05 MB\n",
            "Modified: 2026-02-10T03:26:51.000Z\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Select first file for testing\n",
        "test_file = pdf_files[0]\n",
        "\n",
        "print(\"üìÑ Selected Test File:\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Province: {test_file['province_name']}\")\n",
        "print(f\"Path: {test_file['path']}\")\n",
        "print(f\"File ID: {test_file['file_id']}\")\n",
        "print(f\"Size: {test_file['size_mb']:.2f} MB\")\n",
        "print(f\"Modified: {test_file['mod_time']}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Updated extraction function - uses ddtrace for LLM observability\n"
          ]
        }
      ],
      "source": [
        "@task\n",
        "def extract_from_drive_url(\n",
        "    file_info: dict,\n",
        "    config = None,\n",
        ") -> list[dict]:\n",
        "    \"\"\"\n",
        "    Extract vote data from a PDF file stored in Google Drive.\n",
        "    \n",
        "    Args:\n",
        "        file_info: Dictionary containing file metadata from BigQuery with keys:\n",
        "            - file_id: Google Drive file ID\n",
        "            - province_name: Province name\n",
        "            - path: File path\n",
        "            - size_mb: File size in MB\n",
        "            - folder_id: Google Drive folder ID\n",
        "        config: ExperimentConfig or dict with model, temperature, max_tokens, thinking_mode.\n",
        "                If None, uses defaults (MODEL_NAME, temp=0.0, max_tokens=8192)\n",
        "    \n",
        "    Returns:\n",
        "        List of extracted election form data with file_info embedded\n",
        "    \"\"\"\n",
        "    # Use config or defaults\n",
        "    if config is None:\n",
        "        config = ExperimentConfig(model=MODEL_NAME, temperature=0.0, max_tokens=8192)\n",
        "    elif isinstance(config, dict):\n",
        "        # Convert dict to ExperimentConfig\n",
        "        config = ExperimentConfig(**config)\n",
        "    \n",
        "    # Extract file_id and construct drive_uri\n",
        "    file_id = file_info['file_id']\n",
        "    drive_uri = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "    \n",
        "    print(f\"ü§ñ Extracting with {config.model}...\")\n",
        "    print(f\"   Temperature: {config.temperature}, Max tokens: {config.max_tokens}\")\n",
        "    if config.thinking_mode:\n",
        "        print(f\"   Thinking mode: {config.thinking_mode}\")\n",
        "    print(f\"   Province: {file_info.get('province_name', 'N/A')}\")\n",
        "    print(f\"   File: {file_info.get('path', 'N/A')}\")\n",
        "    print(f\"   Size: {file_info.get('size_mb', 0):.2f} MB\")\n",
        "    print(f\"   Using Google Drive URI (External URL method)\")\n",
        "    \n",
        "    # Create file part from URI\n",
        "    file_part = types.Part.from_uri(\n",
        "        file_uri=drive_uri,\n",
        "        mime_type=\"application/pdf\"\n",
        "    )\n",
        "    \n",
        "    # Enhanced extraction prompt\n",
        "    prompt = \"\"\"\n",
        "    You are an expert data entry assistant for Thai Election documents (Form S.S. 5/18).\n",
        "    \n",
        "    CRITICAL INSTRUCTIONS:\n",
        "    \n",
        "    1. **Analyze all pages** of this PDF document carefully.\n",
        "    \n",
        "    2. **Extract BOTH number formats** for all numerical values:\n",
        "       - Arabic numerals (e.g., 120)\n",
        "       - Thai text (e.g., \"‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏£‡πâ‡∏≠‡∏¢‡∏¢‡∏µ‡πà‡∏™‡∏¥‡∏ö\")\n",
        "       This applies to: voter statistics, ballot statistics, vote counts, and total votes.\n",
        "    \n",
        "    3. **Header Information** (usually on first page):\n",
        "       - Form type: \"Constituency\" (‡πÅ‡∏ö‡∏ö‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏Ç‡∏ï) or \"PartyList\" (‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠)\n",
        "       - Set number (‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà) if present\n",
        "       - Date, Province, District, Sub-district\n",
        "       - Polling station number (‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà)\n",
        "       - Village number (‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà) if present\n",
        "    \n",
        "    4. **Section 1 - Voter Statistics:**\n",
        "       - 1.1 Eligible voters (‡∏ú‡∏π‡πâ‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏ï‡∏≤‡∏°‡∏ö‡∏±‡∏ç‡∏ä‡∏µ)\n",
        "       - 1.2 Present voters (‡∏ú‡∏π‡πâ‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏ô)\n",
        "       Extract both arabic and thai_text for each.\n",
        "    \n",
        "    5. **Section 2 - Ballot Statistics:**\n",
        "       - 2.1 Allocated ballots (‡∏ö‡∏±‡∏ï‡∏£‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£)\n",
        "       - 2.2 Used ballots (‡∏ö‡∏±‡∏ï‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ)\n",
        "       - 2.2.1 Valid ballots (‡∏ö‡∏±‡∏ï‡∏£‡∏î‡∏µ)\n",
        "       - 2.2.2 Invalid ballots (‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏™‡∏µ‡∏¢)\n",
        "       - 2.2.3 No vote ballots (‡πÑ‡∏°‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)\n",
        "       - 2.3 Remaining ballots (‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏´‡∏•‡∏∑‡∏≠)\n",
        "       Extract both arabic and thai_text for each.\n",
        "    \n",
        "    6. **Section 3 - Vote Results Table:**\n",
        "       - Consolidate all pages (table often spans multiple pages)\n",
        "       - For each entry: number, candidate name (if Constituency), party name, vote count\n",
        "       - Extract vote_count as {arabic: int, thai_text: str}\n",
        "    \n",
        "    7. **Total Votes Recorded:**\n",
        "       - Look for \"‡∏£‡∏ß‡∏°\" (total) at the bottom of the vote results table\n",
        "       - Extract both arabic and thai_text\n",
        "    \n",
        "    8. **Officials (Committee Members):**\n",
        "       - Extract names and positions from signature section\n",
        "       - Common positions: ‡∏õ‡∏£‡∏∞‡∏ò‡∏≤‡∏ô (Chair), ‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£ (Member), ‡πÄ‡∏•‡∏Ç‡∏≤‡∏ô‡∏∏‡∏Å‡∏≤‡∏£ (Secretary)\n",
        "    \n",
        "    9. **Validation:**\n",
        "       - ballots_used.arabic = good_ballots.arabic + bad_ballots.arabic + no_vote_ballots.arabic\n",
        "       - total_votes_recorded.arabic = sum of all vote_count.arabic\n",
        "    \"\"\"\n",
        "    \n",
        "    # Configure generation\n",
        "    gen_config_params = {\n",
        "        \"response_mime_type\": \"application/json\",\n",
        "        \"response_schema\": ELECTION_DATA_SCHEMA,\n",
        "        \"temperature\": config.temperature,\n",
        "        \"max_output_tokens\": config.max_tokens,\n",
        "        \"top_p\": 0.95,\n",
        "        \"top_k\": 40,\n",
        "    }\n",
        "    \n",
        "    # Add thinking_mode if supported\n",
        "    if config.thinking_mode:\n",
        "        gen_config_params[\"thinking_mode\"] = config.thinking_mode\n",
        "    \n",
        "    generation_config = types.GenerateContentConfig(**gen_config_params)\n",
        "    \n",
        "    # Generate content (ddtrace will automatically capture this as LLM trace)\n",
        "    print(\"   Sending request to Gemini...\")\n",
        "    response = gemini_client.models.generate_content(\n",
        "        model=config.model,\n",
        "        contents=[file_part, prompt],\n",
        "        config=generation_config,\n",
        "    )\n",
        "    \n",
        "    # Parse response\n",
        "    result = json.loads(response.text)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Extraction complete!\")\n",
        "    print(f\"   Extracted {len(result)} report(s)\")\n",
        "    \n",
        "    # Add file_info to each report in result\n",
        "    for report in result:\n",
        "        report['file_info'] = file_info\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "print(\"‚úÖ Updated extraction function - uses ddtrace for LLM observability\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "@task\n",
        "def extraction_task(input_data, config=None) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Task wrapper for LLMObs experiments.\n",
        "    \n",
        "    Args:\n",
        "        input_data: File metadata from dataset (contains file_info)\n",
        "        config: Optional experiment configuration (ExperimentConfig or None)\n",
        "    \n",
        "    Returns:\n",
        "        List of extracted reports with file_info\n",
        "    \"\"\"\n",
        "    # Use config or create default\n",
        "    if config is None:\n",
        "        config = ExperimentConfig(model=MODEL_NAME, temperature=0.0, max_tokens=8192)\n",
        "    elif isinstance(config, dict):\n",
        "        # Convert dict to ExperimentConfig\n",
        "        config = ExperimentConfig(**config)\n",
        "    \n",
        "    return extract_from_drive_url(input_data, config=config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Experiments with Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. LLMObs Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ LLMObs Experiments Setup\n",
            "\n",
            "Dataset: 5 items\n",
            "Configurations: 10\n",
            "ML App: gemini-ss5_18\n",
            "Project: vote-extraction-project\n",
            "\n",
            "Available configurations:\n",
            "  1. gemini-3-flash-preview (thinking: LOW)\n",
            "  2. gemini-3-flash-preview (thinking: HIGH)\n",
            "  3. gemini-3-pro-preview (thinking: LOW)\n",
            "  4. gemini-3-pro-preview (thinking: HIGH)\n",
            "  5. gemini-2.5-flash\n",
            "  6. gemini-3-flash-preview (thinking: LOW)\n",
            "  7. gemini-3-flash-preview (thinking: HIGH)\n",
            "  8. gemini-3-pro-preview (thinking: LOW)\n",
            "  9. gemini-3-pro-preview (thinking: HIGH)\n",
            "  10. gemini-2.5-flash\n",
            "\n",
            "================================================================================\n",
            "CHOOSE AN OPTION:\n",
            "================================================================================\n",
            "\n",
            "Option 1: Run single experiment (recommended for testing)\n",
            "  experiment = run_single_experiment(EXPERIMENT_CONFIGS[0], dataset)\n",
            "\n",
            "Option 2: Run specific configuration\n",
            "  # Example: Test gemini-3-flash-preview with thinking LOW\n",
            "  config = EXPERIMENT_CONFIGS[0]\n",
            "  experiment = run_single_experiment(config, dataset)\n",
            "\n",
            "Option 3: Run all experiments (takes longer)\n",
            "  experiments = run_all_experiments(dataset, EXPERIMENT_CONFIGS)\n",
            "\n",
            "Option 4: Run subset of experiments\n",
            "  # Test only gemini-3 models\n",
            "  gemini3_configs = [c for c in EXPERIMENT_CONFIGS if 'gemini-3' in c.model]\n",
            "  experiments = run_all_experiments(dataset, gemini3_configs)\n",
            "\n",
            "================================================================================\n",
            "üí° Uncomment one of the options below to run:\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üöÄ Running Multiple Experiments\n",
            "================================================================================\n",
            "\n",
            "Total configurations: 10\n",
            "Dataset items: 5\n",
            "Total experiments: 10\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Experiment 1/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_flash_preview_thinking_LOW_temp0.0\n",
            "   Model: gemini-3-flash-preview\n",
            "   Temperature: 0.0\n",
            "   Thinking mode: LOW\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_flash_preview_thinking_LOW_temp0.0\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 2/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_flash_preview_thinking_HIGH_temp0.0\n",
            "   Model: gemini-3-flash-preview\n",
            "   Temperature: 0.0\n",
            "   Thinking mode: HIGH\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_flash_preview_thinking_HIGH_temp0.0\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 3/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_pro_preview_thinking_LOW_temp0.0\n",
            "   Model: gemini-3-pro-preview\n",
            "   Temperature: 0.0\n",
            "   Thinking mode: LOW\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_pro_preview_thinking_LOW_temp0.0\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 4/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_pro_preview_thinking_HIGH_temp0.0\n",
            "   Model: gemini-3-pro-preview\n",
            "   Temperature: 0.0\n",
            "   Thinking mode: HIGH\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_pro_preview_thinking_HIGH_temp0.0\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 5/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_2_5_flash_temp0.0\n",
            "   Model: gemini-2.5-flash\n",
            "   Temperature: 0.0\n",
            "   Thinking mode: N/A\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_2_5_flash_temp0.0\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 6/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_flash_preview_thinking_LOW_temp0.5\n",
            "   Model: gemini-3-flash-preview\n",
            "   Temperature: 0.5\n",
            "   Thinking mode: LOW\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_flash_preview_thinking_LOW_temp0.5\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 7/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_flash_preview_thinking_HIGH_temp0.5\n",
            "   Model: gemini-3-flash-preview\n",
            "   Temperature: 0.5\n",
            "   Thinking mode: HIGH\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_flash_preview_thinking_HIGH_temp0.5\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 8/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_pro_preview_thinking_LOW_temp0.5\n",
            "   Model: gemini-3-pro-preview\n",
            "   Temperature: 0.5\n",
            "   Thinking mode: LOW\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_pro_preview_thinking_LOW_temp0.5\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 9/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_pro_preview_thinking_HIGH_temp0.5\n",
            "   Model: gemini-3-pro-preview\n",
            "   Temperature: 0.5\n",
            "   Thinking mode: HIGH\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_pro_preview_thinking_HIGH_temp0.5\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 10/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_2_5_flash_temp0.5\n",
            "   Model: gemini-2.5-flash\n",
            "   Temperature: 0.5\n",
            "   Thinking mode: N/A\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_2_5_flash_temp0.5\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "\n",
            "================================================================================\n",
            "‚úÖ All experiments completed: 10/10 successful\n",
            "================================================================================\n",
            "\n",
            "üí° View results in Datadog LLMObs dashboard\n",
            "   Project: vote-extraction-project\n",
            "   ML App: gemini-ss5_18\n",
            "Select and uncomment one option above, then run this cell.\n"
          ]
        }
      ],
      "source": [
        "# Run experiments using LLMObs.experiment() API\n",
        "\n",
        "print(\"üöÄ LLMObs Experiments Setup\\n\")\n",
        "print(f\"Dataset: {len(list(dataset))} items\")\n",
        "print(f\"Configurations: {len(EXPERIMENT_CONFIGS)}\")\n",
        "print(f\"ML App: {ML_APP}\")\n",
        "print(f\"Project: {LLMOBS_PROJECT_NAME}\\n\")\n",
        "\n",
        "print(\"Available configurations:\")\n",
        "for i, config in enumerate(EXPERIMENT_CONFIGS, 1):\n",
        "    thinking = f\" (thinking: {config.thinking_mode})\" if config.thinking_mode else \"\"\n",
        "    print(f\"  {i}. {config.model}{thinking}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CHOOSE AN OPTION:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nOption 1: Run single experiment (recommended for testing)\")\n",
        "print(\"  experiment = run_single_experiment(EXPERIMENT_CONFIGS[0], dataset)\")\n",
        "\n",
        "print(\"\\nOption 2: Run specific configuration\")\n",
        "print(\"  # Example: Test gemini-3-flash-preview with thinking LOW\")\n",
        "print(\"  config = EXPERIMENT_CONFIGS[0]\")\n",
        "print(\"  experiment = run_single_experiment(config, dataset)\")\n",
        "\n",
        "print(\"\\nOption 3: Run all experiments (takes longer)\")\n",
        "print(\"  experiments = run_all_experiments(dataset, EXPERIMENT_CONFIGS)\")\n",
        "\n",
        "print(\"\\nOption 4: Run subset of experiments\")\n",
        "print(\"  # Test only gemini-3 models\")\n",
        "print(\"  gemini3_configs = [c for c in EXPERIMENT_CONFIGS if 'gemini-3' in c.model]\")\n",
        "print(\"  experiments = run_all_experiments(dataset, gemini3_configs)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° Uncomment one of the options below to run:\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# OPTION 1: Single experiment (quick test)\n",
        "# experiment = run_single_experiment(EXPERIMENT_CONFIGS[0], dataset)\n",
        "\n",
        "# OPTION 2: Specific config\n",
        "# config = EXPERIMENT_CONFIGS[1]  # gemini-3-flash-preview (HIGH)\n",
        "# experiment = run_single_experiment(config, dataset)\n",
        "\n",
        "# OPTION 3: All experiments\n",
        "# experiments = run_all_experiments(dataset, EXPERIMENT_CONFIGS)\n",
        "\n",
        "# OPTION 4: Subset (gemini-3 only)\n",
        "# gemini3_configs = [c for c in EXPERIMENT_CONFIGS if 'gemini-3' in c.model]\n",
        "# experiments = run_all_experiments(dataset, gemini3_configs)\n",
        "\n",
        "print(\"Select and uncomment one option above, then run this cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üöÄ Running Multiple Experiments\n",
            "================================================================================\n",
            "\n",
            "Total configurations: 10\n",
            "Dataset items: 5\n",
            "Total experiments: 10\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Experiment 1/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_flash_preview_thinking_LOW_temp0.0\n",
            "   Model: gemini-3-flash-preview\n",
            "   Temperature: 0.0\n",
            "   Thinking mode: LOW\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_flash_preview_thinking_LOW_temp0.0\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 2/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_flash_preview_thinking_HIGH_temp0.0\n",
            "   Model: gemini-3-flash-preview\n",
            "   Temperature: 0.0\n",
            "   Thinking mode: HIGH\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_flash_preview_thinking_HIGH_temp0.0\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 3/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_pro_preview_thinking_LOW_temp0.0\n",
            "   Model: gemini-3-pro-preview\n",
            "   Temperature: 0.0\n",
            "   Thinking mode: LOW\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_pro_preview_thinking_LOW_temp0.0\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 4/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_pro_preview_thinking_HIGH_temp0.0\n",
            "   Model: gemini-3-pro-preview\n",
            "   Temperature: 0.0\n",
            "   Thinking mode: HIGH\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_pro_preview_thinking_HIGH_temp0.0\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 5/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_2_5_flash_temp0.0\n",
            "   Model: gemini-2.5-flash\n",
            "   Temperature: 0.0\n",
            "   Thinking mode: N/A\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_2_5_flash_temp0.0\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 6/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_flash_preview_thinking_LOW_temp0.5\n",
            "   Model: gemini-3-flash-preview\n",
            "   Temperature: 0.5\n",
            "   Thinking mode: LOW\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_flash_preview_thinking_LOW_temp0.5\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 7/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_flash_preview_thinking_HIGH_temp0.5\n",
            "   Model: gemini-3-flash-preview\n",
            "   Temperature: 0.5\n",
            "   Thinking mode: HIGH\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_flash_preview_thinking_HIGH_temp0.5\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 8/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_pro_preview_thinking_LOW_temp0.5\n",
            "   Model: gemini-3-pro-preview\n",
            "   Temperature: 0.5\n",
            "   Thinking mode: LOW\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_pro_preview_thinking_LOW_temp0.5\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 9/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_3_pro_preview_thinking_HIGH_temp0.5\n",
            "   Model: gemini-3-pro-preview\n",
            "   Temperature: 0.5\n",
            "   Thinking mode: HIGH\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_3_pro_preview_thinking_HIGH_temp0.5\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "================================================================================\n",
            "Experiment 10/10\n",
            "================================================================================\n",
            "\n",
            "üöÄ Running experiment: gemini_2_5_flash_temp0.5\n",
            "   Model: gemini-2.5-flash\n",
            "   Temperature: 0.5\n",
            "   Thinking mode: N/A\n",
            "   Dataset items: 5\n",
            "\n",
            "\n",
            "‚úÖ Experiment completed: gemini_2_5_flash_temp0.5\n",
            "   Results available in Datadog LLMObs dashboard\n",
            "\n",
            "\n",
            "================================================================================\n",
            "‚úÖ All experiments completed: 10/10 successful\n",
            "================================================================================\n",
            "\n",
            "üí° View results in Datadog LLMObs dashboard\n",
            "   Project: vote-extraction-project\n",
            "   ML App: gemini-ss5_18\n"
          ]
        }
      ],
      "source": [
        "experiments = run_all_experiments(dataset, EXPERIMENT_CONFIGS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View experiment results summary\n",
        "# Run this after experiments complete\n",
        "\n",
        "if 'experiment' in locals():\n",
        "    print(\"üìä Single Experiment Results\\n\")\n",
        "    print(f\"Experiment: {experiment}\")\n",
        "    print(f\"\\nüí° View detailed results in Datadog LLMObs dashboard:\")\n",
        "    print(f\"   Project: {LLMOBS_PROJECT_NAME}\")\n",
        "    print(f\"   ML App: {ML_APP}\")\n",
        "    print(f\"\\nThe experiment has been submitted to Datadog LLMObs.\")\n",
        "    print(f\"Results will be available in the dashboard shortly.\")\n",
        "    \n",
        "elif 'experiments' in locals() and experiments:\n",
        "    print(\"üìä Multiple Experiments Results\\n\")\n",
        "    print(f\"Total experiments completed: {len(experiments)}\\n\")\n",
        "    \n",
        "    print(\"Experiments:\")\n",
        "    for i, exp in enumerate(experiments, 1):\n",
        "        print(f\"  {i}. {exp}\")\n",
        "    \n",
        "    print(f\"\\nüí° View detailed results in Datadog LLMObs dashboard:\")\n",
        "    print(f\"   Project: {LLMOBS_PROJECT_NAME}\")\n",
        "    print(f\"   ML App: {ML_APP}\")\n",
        "    \n",
        "    print(f\"\\nAll {len(experiments)} experiments have been submitted to Datadog LLMObs.\")\n",
        "    print(f\"Results and comparisons will be available in the dashboard shortly.\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìà What to check in Datadog LLMObs:\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"  1. Evaluation scores for each configuration\")\n",
        "    print(\"  2. Pass/fail rates per evaluator\")\n",
        "    print(\"  3. Token usage and costs\")\n",
        "    print(\"  4. Thinking mode performance comparison\")\n",
        "    print(\"  5. Model-by-model accuracy breakdown\")\n",
        "    print(\"  6. Individual trace details for debugging\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No experiments found.\")\n",
        "    print(\"\\nRun the cell above to start experiments first.\")\n",
        "    print(\"\\nAfter experiments complete, this cell will show a summary.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = extract_from_drive_url(\n",
        "    file_info=test_file,\n",
        "    model=MODEL_NAME,\n",
        "    temperature=0.0,\n",
        "    max_tokens=32000,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Viewing Results in Datadog\n",
        "\n",
        "After running experiments, view comprehensive results in **Datadog LLMObs Dashboard**:\n",
        "\n",
        "**What you'll see:**\n",
        "- ‚úÖ **Experiment Comparison**: Side-by-side performance metrics\n",
        "- ‚úÖ **Evaluation Scores**: Ballot, voter, and total votes accuracy\n",
        "- ‚úÖ **Pass/Fail Rates**: For each evaluator across configs\n",
        "- ‚úÖ **Token Usage**: Cost analysis per configuration\n",
        "- ‚úÖ **Thinking Mode Impact**: LOW vs HIGH performance\n",
        "- ‚úÖ **Individual Traces**: Debug specific extractions\n",
        "\n",
        "**Key Metrics:**\n",
        "1. **ballot_statistics**: Correctness of ballot counts (‚â•85% = pass)\n",
        "2. **voter_statistics**: Accuracy of voter numbers (100% = pass)\n",
        "3. **total_votes**: Sum validation and expected match (100% = pass)\n",
        "\n",
        "**Dashboard URL**: Check your Datadog account ‚Üí LLM Observability ‚Üí Experiments\n",
        "\n",
        "**Filter by:**\n",
        "- Project: `{LLMOBS_PROJECT_NAME}`\n",
        "- ML App: `{ML_APP}`\n",
        "- Dataset: `ss5_18_nuttee`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Display Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_number_value(num_obj) -> int:\n",
        "    \"\"\"Extract arabic number from NumberTextPair or plain int.\"\"\"\n",
        "    if isinstance(num_obj, dict):\n",
        "        return num_obj.get('arabic', 0)\n",
        "    elif isinstance(num_obj, int):\n",
        "        return num_obj\n",
        "    return 0\n",
        "\n",
        "\n",
        "def get_thai_text(num_obj) -> str:\n",
        "    \"\"\"Extract Thai text from NumberTextPair or return empty string.\"\"\"\n",
        "    if isinstance(num_obj, dict):\n",
        "        return num_obj.get('thai_text', '')\n",
        "    return ''\n",
        "\n",
        "\n",
        "def display_results(result: list[dict]):\n",
        "    \"\"\"Display enhanced extraction results with NumberTextPair support.\"\"\"\n",
        "    if not result:\n",
        "        print(\"‚ùå No data extracted\")\n",
        "        return\n",
        "    \n",
        "    for idx, report in enumerate(result, 1):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"REPORT #{idx}\")\n",
        "        print(f\"{'='*80}\")\n",
        "        \n",
        "        # Form Info\n",
        "        form_info = report.get(\"form_info\", {})\n",
        "        print(f\"\\nüìã FORM INFORMATION\")\n",
        "        print(f\"   Form Type: {form_info.get('form_type', 'N/A')}\")\n",
        "        \n",
        "        # Show set_number if available\n",
        "        if form_info.get('set_number'):\n",
        "            print(f\"   Set Number: {form_info.get('set_number')}\")\n",
        "        \n",
        "        print(f\"   Province: {form_info.get('province', 'N/A')}\")\n",
        "        print(f\"   District: {form_info.get('district', 'N/A')}\")\n",
        "        \n",
        "        if form_info.get('sub_district'):\n",
        "            print(f\"   Sub-district: {form_info.get('sub_district')}\")\n",
        "        \n",
        "        print(f\"   Station: {form_info.get('polling_station_number', 'N/A')}\")\n",
        "        \n",
        "        # Show village_moo if available\n",
        "        if form_info.get('village_moo'):\n",
        "            print(f\"   Village (‡∏´‡∏°‡∏π‡πà): {form_info.get('village_moo')}\")\n",
        "        \n",
        "        if form_info.get('date'):\n",
        "            print(f\"   Date: {form_info.get('date')}\")\n",
        "        \n",
        "        # Voter Statistics\n",
        "        voter_stats = report.get(\"voter_statistics\")\n",
        "        if voter_stats and (voter_stats.get(\"eligible_voters\") or voter_stats.get(\"present_voters\")):\n",
        "            print(f\"\\nüë• VOTER STATISTICS\")\n",
        "            \n",
        "            eligible = voter_stats.get(\"eligible_voters\")\n",
        "            if eligible:\n",
        "                arabic = get_number_value(eligible)\n",
        "                thai = get_thai_text(eligible)\n",
        "                if thai:\n",
        "                    print(f\"   Eligible: {arabic:,} ({thai})\")\n",
        "                else:\n",
        "                    print(f\"   Eligible: {arabic:,}\")\n",
        "            \n",
        "            present = voter_stats.get(\"present_voters\")\n",
        "            if present:\n",
        "                arabic = get_number_value(present)\n",
        "                thai = get_thai_text(present)\n",
        "                if thai:\n",
        "                    print(f\"   Present: {arabic:,} ({thai})\")\n",
        "                else:\n",
        "                    print(f\"   Present: {arabic:,}\")\n",
        "        \n",
        "        # Ballot Statistics\n",
        "        ballot_stats = report.get(\"ballot_statistics\")\n",
        "        if ballot_stats:\n",
        "            print(f\"\\nüì¶ BALLOT STATISTICS\")\n",
        "            \n",
        "            # Extract values safely\n",
        "            used = get_number_value(ballot_stats.get('ballots_used'))\n",
        "            good = get_number_value(ballot_stats.get('good_ballots'))\n",
        "            bad = get_number_value(ballot_stats.get('bad_ballots'))\n",
        "            no_vote = get_number_value(ballot_stats.get('no_vote_ballots'))\n",
        "            allocated = get_number_value(ballot_stats.get('ballots_allocated'))\n",
        "            remaining = get_number_value(ballot_stats.get('ballots_remaining'))\n",
        "            \n",
        "            if allocated > 0:\n",
        "                print(f\"   Allocated: {allocated:,}\")\n",
        "            if used > 0:\n",
        "                print(f\"   Used: {used:,}\")\n",
        "            if good > 0:\n",
        "                print(f\"   - Good: {good:,}\")\n",
        "            if bad > 0:\n",
        "                print(f\"   - Bad: {bad:,}\")\n",
        "            if no_vote > 0:\n",
        "                print(f\"   - No Vote: {no_vote:,}\")\n",
        "            if remaining > 0:\n",
        "                print(f\"   Remaining: {remaining:,}\")\n",
        "            \n",
        "            # Validation\n",
        "            if used > 0 and (good > 0 or bad > 0 or no_vote > 0):\n",
        "                expected = good + bad + no_vote\n",
        "                if used == expected:\n",
        "                    print(f\"   ‚úÖ Validation: PASSED ({used:,} = {expected:,})\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  Validation: FAILED ({used:,} ‚â† {expected:,})\")\n",
        "        \n",
        "        # Vote Results\n",
        "        vote_results = report.get(\"vote_results\", [])\n",
        "        if vote_results:\n",
        "            print(f\"\\nüìä VOTE RESULTS ({len(vote_results)} entries)\")\n",
        "            \n",
        "            # Create DataFrame\n",
        "            df_data = []\n",
        "            for v in vote_results:\n",
        "                vote_count_obj = v.get(\"vote_count\")\n",
        "                vote_arabic = get_number_value(vote_count_obj)\n",
        "                vote_thai = get_thai_text(vote_count_obj)\n",
        "                \n",
        "                row = {\n",
        "                    \"#\": v.get(\"number\"),\n",
        "                    \"Candidate\": v.get(\"candidate_name\") or \"-\",\n",
        "                    \"Party\": v.get(\"party_name\") or \"-\",\n",
        "                    \"Votes\": vote_arabic,\n",
        "                }\n",
        "                \n",
        "                # Add Thai text column if any results have it\n",
        "                if vote_thai:\n",
        "                    row[\"Votes (Thai)\"] = vote_thai[:30] + \"...\" if len(vote_thai) > 30 else vote_thai\n",
        "                \n",
        "                df_data.append(row)\n",
        "            \n",
        "            df = pd.DataFrame(df_data)\n",
        "            display(df)\n",
        "            \n",
        "            # Calculate total\n",
        "            total = df[\"Votes\"].sum()\n",
        "            print(f\"\\n   Calculated Total: {total:,}\")\n",
        "            \n",
        "            # Show recorded total if available\n",
        "            total_recorded = report.get(\"total_votes_recorded\")\n",
        "            if total_recorded:\n",
        "                recorded_arabic = get_number_value(total_recorded)\n",
        "                recorded_thai = get_thai_text(total_recorded)\n",
        "                \n",
        "                if recorded_thai:\n",
        "                    print(f\"   Recorded Total: {recorded_arabic:,} ({recorded_thai})\")\n",
        "                else:\n",
        "                    print(f\"   Recorded Total: {recorded_arabic:,}\")\n",
        "                \n",
        "                # Validation\n",
        "                if total == recorded_arabic:\n",
        "                    print(f\"   ‚úÖ Total validation: PASSED\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  Total validation: FAILED ({total:,} ‚â† {recorded_arabic:,})\")\n",
        "        \n",
        "        # Officials\n",
        "        officials = report.get(\"officials\")\n",
        "        if officials and len(officials) > 0:\n",
        "            print(f\"\\nüëî COMMITTEE MEMBERS ({len(officials)} members)\")\n",
        "            for i, official in enumerate(officials[:10], 1):  # Show max 10\n",
        "                name = official.get('name', 'N/A')\n",
        "                position = official.get('position', 'N/A')\n",
        "                print(f\"   {i}. {name} - {position}\")\n",
        "            \n",
        "            if len(officials) > 10:\n",
        "                print(f\"   ... and {len(officials) - 10} more\")\n",
        "\n",
        "\n",
        "# Display results\n",
        "try:\n",
        "    display_results(result)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error displaying results: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    \n",
        "    # Show raw result for debugging\n",
        "    print(\"\\nüîç Raw result (first 500 chars):\")\n",
        "    print(json.dumps(result, ensure_ascii=False, indent=2)[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_extraction(data: dict) -> tuple[bool, list[str]]:\n",
        "    \"\"\"\n",
        "    Enhanced validation with NumberTextPair support.\n",
        "    \n",
        "    Args:\n",
        "        data: Extracted form data\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (is_valid, list of error messages)\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    warnings = []\n",
        "    \n",
        "    # 1. Ballot statistics validation\n",
        "    ballot_stats = data.get(\"ballot_statistics\")\n",
        "    if ballot_stats:\n",
        "        used = get_number_value(ballot_stats.get(\"ballots_used\"))\n",
        "        good = get_number_value(ballot_stats.get(\"good_ballots\"))\n",
        "        bad = get_number_value(ballot_stats.get(\"bad_ballots\"))\n",
        "        no_vote = get_number_value(ballot_stats.get(\"no_vote_ballots\"))\n",
        "        \n",
        "        expected_total = good + bad + no_vote\n",
        "        \n",
        "        if used != expected_total:\n",
        "            errors.append(\n",
        "                f\"Ballot mismatch: ballots_used ({used:,}) != \"\n",
        "                f\"good+bad+no_vote ({expected_total:,})\"\n",
        "            )\n",
        "    \n",
        "    # 2. Total votes validation (NEW!)\n",
        "    vote_results = data.get(\"vote_results\", [])\n",
        "    total_recorded = data.get(\"total_votes_recorded\")\n",
        "    \n",
        "    if vote_results and total_recorded:\n",
        "        # Sum up all vote counts\n",
        "        calculated_total = sum(get_number_value(v.get(\"vote_count\")) for v in vote_results)\n",
        "        recorded_total = get_number_value(total_recorded)\n",
        "        \n",
        "        if calculated_total != recorded_total:\n",
        "            errors.append(\n",
        "                f\"Vote total mismatch: sum of votes ({calculated_total:,}) != \"\n",
        "                f\"recorded total ({recorded_total:,})\"\n",
        "            )\n",
        "    \n",
        "    # 3. Voter statistics vs ballot statistics (NEW!)\n",
        "    voter_stats = data.get(\"voter_statistics\")\n",
        "    if voter_stats and ballot_stats:\n",
        "        present = get_number_value(voter_stats.get(\"present_voters\"))\n",
        "        used = get_number_value(ballot_stats.get(\"ballots_used\"))\n",
        "        \n",
        "        # Present voters should roughly match ballots used (allow small discrepancy)\n",
        "        discrepancy = abs(present - used)\n",
        "        if discrepancy > 5:\n",
        "            warnings.append(\n",
        "                f\"Voter count ({present:,}) differs from ballots used ({used:,}) by {discrepancy}\"\n",
        "            )\n",
        "    \n",
        "    # 4. Vote count non-negative check\n",
        "    for i, result in enumerate(vote_results, 1):\n",
        "        vote_count = get_number_value(result.get(\"vote_count\"))\n",
        "        if vote_count < 0:\n",
        "            name = result.get(\"candidate_name\") or result.get(\"party_name\") or f\"Entry #{i}\"\n",
        "            errors.append(f\"Negative vote count for {name}: {vote_count}\")\n",
        "    \n",
        "    # 5. Check for empty vote results\n",
        "    if not vote_results:\n",
        "        errors.append(\"No vote results extracted\")\n",
        "    \n",
        "    # Display results\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"VALIDATION RESULTS\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    if errors:\n",
        "        print(f\"\\n‚ùå ERRORS ({len(errors)}):\")\n",
        "        for error in errors:\n",
        "            print(f\"   - {error}\")\n",
        "    \n",
        "    if warnings:\n",
        "        print(f\"\\n‚ö†Ô∏è  WARNINGS ({len(warnings)}):\")\n",
        "        for warning in warnings:\n",
        "            print(f\"   - {warning}\")\n",
        "    \n",
        "    if not errors and not warnings:\n",
        "        print(f\"\\n‚úÖ All validation checks PASSED!\")\n",
        "    elif not errors:\n",
        "        print(f\"\\n‚úÖ No errors, but {len(warnings)} warning(s)\")\n",
        "    \n",
        "    return len(errors) == 0, errors\n",
        "\n",
        "\n",
        "# Run validation on extracted data\n",
        "is_valid, errors = validate_extraction(result[0] if result else {})\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Overall: {'‚úÖ VALID' if is_valid else '‚ùå INVALID'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate each report with enhanced Pydantic models\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PYDANTIC MODEL VALIDATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for idx, report_data in enumerate(result, 1):\n",
        "    try:\n",
        "        # Parse into Pydantic model\n",
        "        form_data = ElectionFormData(**report_data)\n",
        "        \n",
        "        print(f\"\\n‚úÖ Report #{idx} - Pydantic validation PASSED\")\n",
        "        print(f\"   Form Type: {form_data.form_info.form_type}\")\n",
        "        print(f\"   District: {form_data.form_info.district}\")\n",
        "        print(f\"   Set Number: {form_data.form_info.set_number or 'N/A'}\")\n",
        "        print(f\"   Village: {form_data.form_info.village_moo or 'N/A'}\")\n",
        "        \n",
        "        # Show voter statistics if available\n",
        "        if form_data.voter_statistics:\n",
        "            if form_data.voter_statistics.eligible_voters:\n",
        "                print(f\"   Eligible Voters: {form_data.voter_statistics.eligible_voters.arabic:,}\")\n",
        "            if form_data.voter_statistics.present_voters:\n",
        "                print(f\"   Present Voters: {form_data.voter_statistics.present_voters.arabic:,}\")\n",
        "        \n",
        "        # Show ballot statistics\n",
        "        if form_data.ballot_statistics and form_data.ballot_statistics.ballots_used:\n",
        "            print(f\"   Ballots Used: {form_data.ballot_statistics.ballots_used.arabic:,}\")\n",
        "        \n",
        "        # Show vote results count\n",
        "        print(f\"   Vote Results: {len(form_data.vote_results)} entries\")\n",
        "        \n",
        "        # Show total votes if available\n",
        "        if form_data.total_votes_recorded:\n",
        "            print(f\"   Total Votes: {form_data.total_votes_recorded.arabic:,}\")\n",
        "        \n",
        "        # Show officials count if available\n",
        "        if form_data.officials:\n",
        "            print(f\"   Officials: {len(form_data.officials)} members\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Report #{idx} - Pydantic validation FAILED\")\n",
        "        print(f\"   Error: {e}\")\n",
        "        \n",
        "        # Show which field caused the error\n",
        "        import traceback\n",
        "        error_details = traceback.format_exc()\n",
        "        if \"Field required\" in str(e):\n",
        "            print(f\"   Hint: Missing required field\")\n",
        "        elif \"validation error\" in str(e).lower():\n",
        "            print(f\"   Hint: Data type mismatch\")\n",
        "        \n",
        "        # Show first few lines of error for debugging\n",
        "        error_lines = error_details.split('\\n')\n",
        "        relevant_lines = [line for line in error_lines if 'Field' in line or 'validation' in line.lower()]\n",
        "        if relevant_lines:\n",
        "            print(f\"   Details: {relevant_lines[0][:100]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Validate with Pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate each report\n",
        "for idx, report_data in enumerate(result, 1):\n",
        "    try:\n",
        "        form_data = ElectionFormData(**report_data)\n",
        "        print(f\"‚úÖ Report #{idx} - Pydantic validation PASSED\")\n",
        "        print(f\"   Form Type: {form_data.form_info.form_type}\")\n",
        "        print(f\"   District: {form_data.form_info.district}\")\n",
        "        print(f\"   Vote Results: {len(form_data.vote_results)} entries\")\n",
        "        print()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Report #{idx} - Pydantic validation FAILED\")\n",
        "        print(f\"   Error: {e}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. LLMObs Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = LLMObs.create_dataset(\n",
        "    dataset_name=\"ss5_18_nuttee\",\n",
        "    project_name=LLMOBS_PROJECT_NAME, # optional, defaults to project_name used in LLMObs.enable\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = LLMObs.pull_dataset(\n",
        "    dataset_name=\"ss5_18_nuttee\",\n",
        "    project_name=LLMOBS_PROJECT_NAME,\n",
        ")\n",
        "\n",
        "# Get dataset length\n",
        "print(len(dataset))\n",
        "\n",
        "# Convert dataset to pandas DataFrame\n",
        "df = dataset.as_dataframe()\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates the **most efficient workflow** for vote extraction:\n",
        "\n",
        "‚úÖ **BigQuery Integration** - Query metadata to find files  \n",
        "‚úÖ **Google Drive Direct Access** - No local downloads needed!  \n",
        "‚úÖ **External URLs Method** - Gemini fetches files directly  \n",
        "‚úÖ **Structured Output** - Guaranteed JSON schema  \n",
        "‚úÖ **Pydantic Validation** - Type-safe data models  \n",
        "‚úÖ **Datadog LLMObs** - Automatic LLM trace collection  \n",
        "\n",
        "## Key Advantages Over Local PDF Processing:\n",
        "\n",
        "1. **No Local Storage** - Files stay in Google Drive\n",
        "2. **No PDF Conversion** - Gemini handles PDF directly\n",
        "3. **Faster** - No download/upload overhead\n",
        "4. **Scalable** - Easy to process thousands of files\n",
        "5. **Cost Effective** - No egress charges for data transfer\n",
        "6. **Full Observability** - ddtrace captures all LLM interactions\n",
        "\n",
        "## Next Steps:\n",
        "\n",
        "1. **Process by Province** - Filter BigQuery by province\n",
        "2. **Save to BigQuery** - Store results back in BigQuery\n",
        "3. **Error Handling** - Add retry logic for failed extractions\n",
        "4. **Monitoring** - Track processing status via Datadog LLMObs\n",
        "5. **Automation** - Schedule regular processing with Cloud Functions"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
