{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27f059be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[K\u001b[34m⠋\u001b[0m JSON API formula.jws.json                        [Downloading  32.1MB/-------]\n",
      "\u001b[K\u001b[34m⠋\u001b[0m JSON API cask.jws.json                           [Downloading  14.8MB/-------]\u001b[1F\u001b[K\u001b[34m⠋\u001b[0m JSON API formula.jws.json                        [Downloading  32.1MB/-------]\n",
      "\u001b[K\u001b[34m⠋\u001b[0m JSON API cask.jws.json                           [Downloading  14.8MB/-------]\u001b[1F\u001b[K\u001b[34m⠙\u001b[0m JSON API formula.jws.json                        [Downloading  32.1MB/-------]\n",
      "\u001b[K\u001b[34m⠙\u001b[0m JSON API cask.jws.json                           [Downloading  14.8MB/-------]\u001b[1F\u001b[K\u001b[34m⠙\u001b[0m JSON API formula.jws.json                        [Downloading  32.1MB/-------]\n",
      "\u001b[K\u001b[34m⠙\u001b[0m JSON API cask.jws.json                           [Downloading  14.8MB/-------]\u001b[1F\u001b[K\u001b[34m⠚\u001b[0m JSON API formula.jws.json                        [Downloading   2.2MB/-------]\n",
      "\u001b[K\u001b[34m⠚\u001b[0m JSON API cask.jws.json                           [Downloading   2.2MB/-------]\u001b[1F\u001b[K\u001b[34m⠚\u001b[0m JSON API formula.jws.json                        [Downloading   9.2MB/-------]\n",
      "\u001b[K\u001b[34m⠚\u001b[0m JSON API cask.jws.json                           [Downloading   7.6MB/-------]\u001b[1F\u001b[K\u001b[34m⠞\u001b[0m JSON API formula.jws.json                        [Downloading  15.2MB/-------]\n",
      "\u001b[K\u001b[34m⠞\u001b[0m JSON API cask.jws.json                           [Downloading   9.9MB/-------]\u001b[1F\u001b[K\u001b[34m⠞\u001b[0m JSON API formula.jws.json                        [Downloading  19.5MB/-------]\n",
      "\u001b[K\u001b[34m⠞\u001b[0m JSON API cask.jws.json                           [Downloading  11.7MB/-------]\u001b[1F\u001b[K\u001b[34m⠖\u001b[0m JSON API formula.jws.json                        [Downloading  23.1MB/-------]\n",
      "\u001b[K\u001b[34m⠖\u001b[0m JSON API cask.jws.json                           [Downloading  12.8MB/-------]\u001b[1F\u001b[K\u001b[34m⠖\u001b[0m JSON API formula.jws.json                        [Downloading  32.1MB/-------]\n",
      "\u001b[K\u001b[34m⠦\u001b[0m JSON API cask.jws.json                           [Downloaded   14.8MB/ 14.8MB]\u001b[1F\u001b[K\u001b[32m✔︎\u001b[0m JSON API cask.jws.json                           [Downloaded   14.8MB/ 14.8MB]\n",
      "\u001b[K\u001b[34m⠴\u001b[0m JSON API formula.jws.json                        [Downloaded   32.1MB/-------]\u001b[0G\u001b[K\u001b[32m✔︎\u001b[0m JSON API formula.jws.json                        [Downloaded   32.1MB/ 32.1MB]\n",
      "\u001b[?25h\u001b[33mWarning:\u001b[0m poppler 25.12.0 is already installed and up-to-date.\n",
      "To reinstall 25.12.0, run:\n",
      "  brew reinstall poppler\n"
     ]
    }
   ],
   "source": [
    "!brew install poppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcbeff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q requests beautifulsoup4 python-dotenv google-genai pdf2image ddtrace openinference-instrumentation-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb6bb418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, unquote\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def get_pdf_links(target_url):\n",
    "    \"\"\" ดึงลิงก์ PDF ทั้งหมดจากหน้าเว็บ \"\"\"\n",
    "    pdf_links = []\n",
    "    try:\n",
    "        response = requests.get(target_url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link['href']\n",
    "            if href.lower().strip().endswith('.pdf'):\n",
    "                full_url = urljoin(target_url, href)\n",
    "                pdf_links.append(full_url)\n",
    "        return pdf_links\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching links: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_pdfs(pdf_links, pdf_folder):\n",
    "    \"\"\" ดาวน์โหลด PDF ลงโฟลเดอร์ \"\"\"\n",
    "    if not os.path.exists(pdf_folder):\n",
    "        os.makedirs(pdf_folder)\n",
    "    \n",
    "    print(f\"Starting download of {len(pdf_links)} files...\")\n",
    "    \n",
    "    downloaded_files = []\n",
    "    for i, link in enumerate(pdf_links, 1):\n",
    "        try:\n",
    "            filename = unquote(os.path.basename(link))\n",
    "            file_path = os.path.join(pdf_folder, filename)\n",
    "            \n",
    "            # เช็คว่ามีไฟล์อยู่แล้วหรือยัง (จะได้ไม่โหลดซ้ำ)\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"[{i}/{len(pdf_links)}] Downloading: {filename} ...\", end=\" \")\n",
    "                response = requests.get(link, stream=True)\n",
    "                response.raise_for_status()\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                print(\"Done.\")\n",
    "            else:\n",
    "                print(f\"[{i}/{len(pdf_links)}] Skipping (Exists): {filename}\")\n",
    "                \n",
    "            downloaded_files.append(file_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {link}. Error: {e}\")\n",
    "            \n",
    "    return downloaded_files\n",
    "\n",
    "def convert_pdfs_to_images(pdf_files, image_folder, dpi=300):\n",
    "    \"\"\" \n",
    "    แปลงไฟล์ PDF เป็นรูปภาพ (JPG) \n",
    "    Args:\n",
    "        pdf_files (list): รายชื่อ path ของไฟล์ PDF\n",
    "        image_folder (str): โฟลเดอร์ปลายทางที่จะเก็บรูป\n",
    "        dpi (int): ความละเอียดของรูป (300 ชัดเจนดีสำหรับ OCR/Vision AI)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_folder):\n",
    "        os.makedirs(image_folder)\n",
    "        \n",
    "    print(f\"\\nConverting {len(pdf_files)} PDFs to images...\")\n",
    "    \n",
    "    for i, pdf_path in enumerate(pdf_files, 1):\n",
    "        try:\n",
    "            filename = os.path.basename(pdf_path)\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            print(f\"[{i}/{len(pdf_files)}] Converting: {filename} ...\")\n",
    "            \n",
    "            # แปลง PDF เป็น list ของ images (1 หน้า = 1 รูป)\n",
    "            # หมายเหตุ: ถ้า Windows หา poppler ไม่เจอ อาจต้องใส่ poppler_path=r'C:\\path\\to\\poppler\\bin'\n",
    "            pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "            \n",
    "            for page_num, page_image in enumerate(pages, 1):\n",
    "                # ตั้งชื่อไฟล์รูป: ชื่อเดิม_page1.jpg\n",
    "                image_name = f\"{base_name}_page{page_num}.jpg\"\n",
    "                image_path = os.path.join(image_folder, image_name)\n",
    "                \n",
    "                # Save รูปภาพ\n",
    "                page_image.save(image_path, 'JPEG')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {filename}: {e}\")\n",
    "\n",
    "def convert_local_pdfs_to_images(source_dir, destination_dir, dpi=350):\n",
    "    \"\"\"\n",
    "    Reads all PDF files from a source directory and converts them to images.\n",
    "    \n",
    "    Args:\n",
    "        source_dir (str): Path to the folder containing PDF files.\n",
    "        destination_dir (str): Path to the folder where images will be saved.\n",
    "        dpi (int): Resolution of the output images (300 is good for AI/OCR).\n",
    "    \"\"\"\n",
    "    # 1. Create destination directory if it doesn't exist\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "        print(f\"Created output folder: {destination_dir}\")\n",
    "\n",
    "    # 2. Get list of all PDF files in the source directory\n",
    "    # Using list comprehension to filter only .pdf files\n",
    "    pdf_files = [f for f in os.listdir(source_dir) if f.lower().endswith('.pdf')]\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in '{source_dir}'\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files in '{source_dir}'. Starting conversion...\\n\")\n",
    "\n",
    "    # 3. Loop through each PDF and convert\n",
    "    for i, filename in enumerate(pdf_files, 1):\n",
    "        pdf_path = os.path.join(source_dir, filename)\n",
    "        base_name = os.path.splitext(filename)[0]  # Remove .pdf extension\n",
    "        \n",
    "        try:\n",
    "            print(f\"[{i}/{len(pdf_files)}] Converting: {filename} ...\", end=\" \")\n",
    "            \n",
    "            # Convert PDF to list of images (one per page)\n",
    "            # Note: For Windows, you might need: poppler_path=r'C:\\path\\to\\poppler\\bin'\n",
    "            pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "            \n",
    "            # Save each page as an image\n",
    "            for page_num, page_image in enumerate(pages, 1):\n",
    "                image_name = f\"{base_name}_page{page_num}.jpg\"\n",
    "                save_path = os.path.join(destination_dir, image_name)\n",
    "                \n",
    "                page_image.save(save_path, 'JPEG')\n",
    "            \n",
    "            print(f\"Done ({len(pages)} pages)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError converting {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9c1b784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Fetching links...\n",
      "Found 118 PDFs. Proceeding to download.\n",
      "----------------------------------------\n",
      "Starting download of 118 files...\n",
      "[1/118] Skipping (Exists): คู่มือผู้ใช้งานระบบหลังบ้าน_Bangkok-PORTAL.pdf\n",
      "[2/118] Skipping (Exists): บางอ้อ1.pdf\n",
      "[3/118] Skipping (Exists): บางอ้อ17.pdf\n",
      "[4/118] Skipping (Exists): บางพลัด1.pdf\n",
      "[5/118] Skipping (Exists): บางพลัด17.pdf\n",
      "[6/118] Skipping (Exists): บางบำหรุ1.pdf\n",
      "[7/118] Skipping (Exists): บางบำหรุ17.pdf\n",
      "[8/118] Skipping (Exists): บางยี่ขัน1.pdf\n",
      "[9/118] Skipping (Exists): บางยี่ขัน17.pdf\n",
      "[10/118] Skipping (Exists): บางอ้อ2.pdf\n",
      "[11/118] Skipping (Exists): บางอ้อ18.pdf\n",
      "[12/118] Skipping (Exists): บางพลัด2.pdf\n",
      "[13/118] Skipping (Exists): บางพลัด18.pdf\n",
      "[14/118] Skipping (Exists): บางบำหรุ2.pdf\n",
      "[15/118] Skipping (Exists): บางบำหรุ18.pdf\n",
      "[16/118] Skipping (Exists): บางยี่ขัน2.pdf\n",
      "[17/118] Skipping (Exists): บางยี่ขัน18.pdf\n",
      "[18/118] Skipping (Exists): บางอ้อ3.pdf\n",
      "[19/118] Skipping (Exists): บางอ้อ19.pdf\n",
      "[20/118] Skipping (Exists): บางพลัด3.pdf\n",
      "[21/118] Skipping (Exists): บางพลัด19.pdf\n",
      "[22/118] Skipping (Exists): บางบำหรุ3.pdf\n",
      "[23/118] Skipping (Exists): บางบำหรุ19.pdf\n",
      "[24/118] Skipping (Exists): บางยี่ขัน3.pdf\n",
      "[25/118] Skipping (Exists): บางยี่ขัน19.pdf\n",
      "[26/118] Skipping (Exists): บางอ้อ4.pdf\n",
      "[27/118] Skipping (Exists): บางอ้อ20.pdf\n",
      "[28/118] Skipping (Exists): บางพลัด4.pdf\n",
      "[29/118] Skipping (Exists): บางพลัด20.pdf\n",
      "[30/118] Skipping (Exists): บางบำหรุ4.pdf\n",
      "[31/118] Skipping (Exists): บางบำหรุ20.pdf\n",
      "[32/118] Skipping (Exists): บางยี่ขัน4.pdf\n",
      "[33/118] Skipping (Exists): บางยี่ขัน20.pdf\n",
      "[34/118] Skipping (Exists): บางอ้อ5.pdf\n",
      "[35/118] Skipping (Exists): บางอ้อ21.pdf\n",
      "[36/118] Skipping (Exists): บางพลัด5.pdf\n",
      "[37/118] Skipping (Exists): บางพลัด21.pdf\n",
      "[38/118] Skipping (Exists): บางบำหรุ5.pdf\n",
      "[39/118] Skipping (Exists): บางบำหรุ21.pdf\n",
      "[40/118] Skipping (Exists): บางยี่ขัน5.pdf\n",
      "[41/118] Skipping (Exists): บางยี่ขัน21.pdf\n",
      "[42/118] Skipping (Exists): บางอ้อ6.pdf\n",
      "[43/118] Skipping (Exists): บางอ้อ22.pdf\n",
      "[44/118] Skipping (Exists): บางพลัด6.pdf\n",
      "[45/118] Skipping (Exists): บางพลัด22.pdf\n",
      "[46/118] Skipping (Exists): บางบำหรุ6.pdf\n",
      "[47/118] Skipping (Exists): บางบำหรุ22.pdf\n",
      "[48/118] Skipping (Exists): บางยี่ขัน6.pdf\n",
      "[49/118] Skipping (Exists): บางยี่ขัน22.pdf\n",
      "[50/118] Skipping (Exists): บางอ้อ7.pdf\n",
      "[51/118] Skipping (Exists): บางอ้อ23.pdf\n",
      "[52/118] Skipping (Exists): บางพลัด7.pdf\n",
      "[53/118] Skipping (Exists): บางพลัด23.pdf\n",
      "[54/118] Skipping (Exists): บางบำหรุ7.pdf\n",
      "[55/118] Skipping (Exists): บางบำหรุ23.pdf\n",
      "[56/118] Skipping (Exists): บางยี่ขัน7.pdf\n",
      "[57/118] Skipping (Exists): บางยี่ขัน23.pdf\n",
      "[58/118] Skipping (Exists): บางอ้อ8.pdf\n",
      "[59/118] Skipping (Exists): บางอ้อ24.pdf\n",
      "[60/118] Skipping (Exists): บางพลัด8.pdf\n",
      "[61/118] Skipping (Exists): บางพลัด24.pdf\n",
      "[62/118] Skipping (Exists): บางบำหรุ8.pdf\n",
      "[63/118] Skipping (Exists): บางบำหรุ24.pdf\n",
      "[64/118] Skipping (Exists): บางยี่ขัน8.pdf\n",
      "[65/118] Skipping (Exists): บางยี่ขัน24.pdf\n",
      "[66/118] Skipping (Exists): บางอ้อ9.pdf\n",
      "[67/118] Skipping (Exists): บางอ้อ25.pdf\n",
      "[68/118] Skipping (Exists): บางพลัด9.pdf\n",
      "[69/118] Skipping (Exists): บางพลัด25.pdf\n",
      "[70/118] Skipping (Exists): บางบำหรุ9.pdf\n",
      "[71/118] Skipping (Exists): บางยี่ขัน9.pdf\n",
      "[72/118] Skipping (Exists): บางยี่ขัน25.pdf\n",
      "[73/118] Skipping (Exists): บางอ้อ10.pdf\n",
      "[74/118] Skipping (Exists): บางอ้อ26.pdf\n",
      "[75/118] Skipping (Exists): บางพลัด10.pdf\n",
      "[76/118] Skipping (Exists): บางพลัด26.pdf\n",
      "[77/118] Skipping (Exists): บางบำหรุ10.pdf\n",
      "[78/118] Skipping (Exists): บางยี่ขัน10.pdf\n",
      "[79/118] Skipping (Exists): บางยี่ขัน26.pdf\n",
      "[80/118] Skipping (Exists): บางอ้อ11.pdf\n",
      "[81/118] Skipping (Exists): บางอ้อ27.pdf\n",
      "[82/118] Skipping (Exists): บางพลัด11.pdf\n",
      "[83/118] Skipping (Exists): บางพลัด27.pdf\n",
      "[84/118] Skipping (Exists): บางบำหรุ11.pdf\n",
      "[85/118] Skipping (Exists): บางยี่ขัน11.pdf\n",
      "[86/118] Skipping (Exists): บางยี่ขัน27.pdf\n",
      "[87/118] Skipping (Exists): บางอ้อ12.pdf\n",
      "[88/118] Skipping (Exists): บางอ้อ28.pdf\n",
      "[89/118] Skipping (Exists): บางพลัด12.pdf\n",
      "[90/118] Skipping (Exists): บางพลัด28.pdf\n",
      "[91/118] Downloading: บางบำหรุ12.pdf ... Done.\n",
      "[92/118] Skipping (Exists): บางยี่ขัน12.pdf\n",
      "[93/118] Skipping (Exists): บางยี่ขัน28.pdf\n",
      "[94/118] Skipping (Exists): บางอ้อ13.pdf\n",
      "[95/118] Skipping (Exists): บางอ้อ29.pdf\n",
      "[96/118] Skipping (Exists): บางพลัด13.pdf\n",
      "[97/118] Skipping (Exists): บางพลัด29.pdf\n",
      "[98/118] Skipping (Exists): บางบำหรุ13.pdf\n",
      "[99/118] Skipping (Exists): บางยี่ขัน13.pdf\n",
      "[100/118] Skipping (Exists): บางยี่ขัน29.pdf\n",
      "[101/118] Skipping (Exists): บางอ้อ14.pdf\n",
      "[102/118] Skipping (Exists): บางอ้อ30.pdf\n",
      "[103/118] Skipping (Exists): บางพลัด14.pdf\n",
      "[104/118] Skipping (Exists): บางพลัด30.pdf\n",
      "[105/118] Skipping (Exists): บางบำหรุ14.pdf\n",
      "[106/118] Skipping (Exists): บางยี่ขัน14.pdf\n",
      "[107/118] Skipping (Exists): บางยี่ขัน30.pdf\n",
      "[108/118] Skipping (Exists): บางอ้อ15.pdf\n",
      "[109/118] Skipping (Exists): บางพลัด15.pdf\n",
      "[110/118] Skipping (Exists): บางพลัด31.pdf\n",
      "[111/118] Skipping (Exists): บางบำหรุ15.pdf\n",
      "[112/118] Skipping (Exists): บางยี่ขัน15.pdf\n",
      "[113/118] Skipping (Exists): บางยี่ขัน31.pdf\n",
      "[114/118] Skipping (Exists): บางอ้อ16.pdf\n",
      "[115/118] Skipping (Exists): บางพลัด16.pdf\n",
      "[116/118] Skipping (Exists): บางพลัด32.pdf\n",
      "[117/118] Skipping (Exists): บางบำหรุ16.pdf\n",
      "[118/118] Skipping (Exists): บางยี่ขัน16.pdf\n",
      "----------------------------------------\n",
      "All downloads complete. Check the folder: 'assets/ss5-18/ss5-18-pdf'\n"
     ]
    }
   ],
   "source": [
    "# URL to scrape\n",
    "target_url = \"https://webportal.bangkok.go.th/bangphlat/page/sub/26952/%E0%B8%A3%E0%B8%B2%E0%B8%A2%E0%B8%87%E0%B8%B2%E0%B8%99%E0%B8%9C%E0%B8%A5%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%99%E0%B8%B1%E0%B8%9A%E0%B8%84%E0%B8%B0%E0%B9%81%E0%B8%99%E0%B8%99%E0%B8%AA%E0%B8%A1%E0%B8%B2%E0%B8%8A%E0%B8%B4%E0%B8%81%E0%B8%AA%E0%B8%A0%E0%B8%B2%E0%B8%9C%E0%B8%B9%E0%B9%89%E0%B9%81%E0%B8%97%E0%B8%99%E0%B8%A3%E0%B8%B2%E0%B8%A9%E0%B8%8E%E0%B8%A3\"\n",
    "\n",
    "# Name of the folder to save files\n",
    "output_dir = \"assets/ss5-18/ss5-18-pdf\"\n",
    "\n",
    "print(\"Step 1: Fetching links...\")\n",
    "links = get_pdf_links(target_url)\n",
    "\n",
    "if links:\n",
    "    print(f\"Found {len(links)} PDFs. Proceeding to download.\")\n",
    "    print(\"-\" * 40)\n",
    "    # Call the new download function\n",
    "    download_pdfs(links, output_dir)\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"All downloads complete. Check the folder: '{output_dir}'\")\n",
    "else:\n",
    "    print(\"No PDF links found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b89b920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118 PDF files in 'assets/ss5-18/ss5-18-pdf'. Starting conversion...\n",
      "\n",
      "[1/118] Converting: บางยี่ขัน1.pdf ... Done (6 pages)\n",
      "[2/118] Converting: บางยี่ขัน27.pdf ... Done (6 pages)\n",
      "[3/118] Converting: บางยี่ขัน26.pdf ... Done (6 pages)\n",
      "[4/118] Converting: บางบำหรุ1.pdf ... Done (6 pages)\n",
      "[5/118] Converting: บางบำหรุ3.pdf ... Done (6 pages)\n",
      "[6/118] Converting: บางยี่ขัน18.pdf ... Done (6 pages)\n",
      "[7/118] Converting: บางยี่ขัน2.pdf ... Done (6 pages)\n",
      "[8/118] Converting: บางยี่ขัน24.pdf ... Done (6 pages)\n",
      "[9/118] Converting: บางยี่ขัน30.pdf ... Done (6 pages)\n",
      "[10/118] Converting: บางยี่ขัน31.pdf ... Done (6 pages)\n",
      "[11/118] Converting: บางยี่ขัน25.pdf ... Done (6 pages)\n",
      "[12/118] Converting: บางยี่ขัน3.pdf ... Done (6 pages)\n",
      "[13/118] Converting: บางยี่ขัน19.pdf ... Done (6 pages)\n",
      "[14/118] Converting: บางบำหรุ2.pdf ... Done (6 pages)\n",
      "[15/118] Converting: บางบำหรุ6.pdf ... Done (6 pages)\n",
      "[16/118] Converting: บางยี่ขัน21.pdf ... Done (6 pages)\n",
      "[17/118] Converting: บางยี่ขัน7.pdf ... Done (6 pages)\n",
      "[18/118] Converting: บางยี่ขัน6.pdf ... Done (6 pages)\n",
      "[19/118] Converting: บางยี่ขัน20.pdf ... Done (6 pages)\n",
      "[20/118] Converting: บางบำหรุ7.pdf ... Done (6 pages)\n",
      "[21/118] Converting: บางอ้อ8.pdf ... Done (6 pages)\n",
      "[22/118] Converting: บางบำหรุ5.pdf ... Done (6 pages)\n",
      "[23/118] Converting: บางยี่ขัน22.pdf ... Done (6 pages)\n",
      "[24/118] Converting: บางยี่ขัน4.pdf ... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Check if source directory exists before running\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(input_pdf_folder):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mconvert_local_pdfs_to_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_pdf_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_image_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAll operations complete. Check folder: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_image_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 125\u001b[39m, in \u001b[36mconvert_local_pdfs_to_images\u001b[39m\u001b[34m(source_dir, destination_dir, dpi)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pdf_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Converting: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Convert PDF to list of images (one per page)\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# Note: For Windows, you might need: poppler_path=r'C:\\path\\to\\poppler\\bin'\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m pages = \u001b[43mconvert_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Save each page as an image\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page_num, page_image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pages, \u001b[32m1\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/genai-app-python/.venv/lib/python3.13/site-packages/pdf2image/pdf2image.py:251\u001b[39m, in \u001b[36mconvert_from_path\u001b[39m\u001b[34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m uid, proc \u001b[38;5;129;01min\u001b[39;00m processes:\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m         data, err = \u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired:\n\u001b[32m    253\u001b[39m         proc.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:1222\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1219\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1224\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:2154\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2147\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2148\u001b[39m                         stdout, stderr,\n\u001b[32m   2149\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2150\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2151\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2152\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2154\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2155\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2157\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2158\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py:398\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    396\u001b[39m ready = []\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# Change these paths to match your actual folders\n",
    "input_pdf_folder = \"assets/ss5-18/ss5-18-pdf\"       # Source folder with PDFs\n",
    "output_image_folder = \"assets/ss5-18/ss5-18-images\"    # Destination for images\n",
    "\n",
    "# Check if source directory exists before running\n",
    "if os.path.exists(input_pdf_folder):\n",
    "    convert_local_pdfs_to_images(input_pdf_folder, output_image_folder)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"All operations complete. Check folder: '{output_image_folder}'\")\n",
    "else:\n",
    "    print(f\"Error: Source directory '{input_pdf_folder}' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847b702",
   "metadata": {},
   "source": [
    "# Gemini Multi-modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f55051",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q python-dotenv google-genai ddtrace openinference-instrumentation-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b295936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "thread 'tokio-runtime-worker' (20225108) panicked at /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/tokio-1.48.0/src/runtime/io/driver.rs:196:23:\n",
      "unexpected error when polling the I/O driver: Os { code: 9, kind: Uncategorized, message: \"Bad file descriptor\" }\n",
      "note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n",
      "\n",
      "thread 'tokio-runtime-worker' (20225109) panicked at /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/tokio-1.48.0/src/runtime/io/driver.rs:260:27:\n",
      "failed to wake I/O driver: Os { code: 9, kind: Uncategorized, message: \"Bad file descriptor\" }\n"
     ]
    }
   ],
   "source": [
    "!export DD_TRACE_AGENT_URL=http://localhost:8136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cfb4f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41f5280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_CLOUD_PROJECT: datadog-ese-sandbox\n",
      "GOOGLE_CLOUD_LOCATION: global\n",
      "GOOGLE_GENAI_USE_VERTEXAI: True\n",
      "DD_LLMOBS_ENABLED: 1\n",
      "DD_LLMOBS_ML_APP: vote-extractor\n",
      "DD_SITE: datadoghq.com\n",
      "DD_SERVICE: vote-extractor\n",
      "DD_ENV: dev\n",
      "DD_VERSION: 0.0.1\n",
      "DD_TRACE_AGENT_URL: http://localhost:8136\n",
      "DD_TRACE_AGENT_PORT: 8136\n",
      "OTEL_EXPORTER_OTLP_TRACES_PROTOCOL: None\n",
      "OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: None\n",
      "OTEL_EXPORTER_OTLP_TRACES_HEADERS: None\n",
      "OTEL_SERVICE_NAME: None\n"
     ]
    }
   ],
   "source": [
    "print(\"GOOGLE_CLOUD_PROJECT:\", os.getenv(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "print(\"GOOGLE_CLOUD_LOCATION:\", os.getenv(\"GOOGLE_CLOUD_LOCATION\"))\n",
    "print(\"GOOGLE_GENAI_USE_VERTEXAI:\", os.getenv(\"GOOGLE_GENAI_USE_VERTEXAI\"))\n",
    "print(\"DD_LLMOBS_ENABLED:\", os.getenv(\"DD_LLMOBS_ENABLED\"))\n",
    "print(\"DD_LLMOBS_ML_APP:\", os.getenv(\"DD_LLMOBS_ML_APP\"))\n",
    "print(\"DD_SITE:\", os.getenv(\"DD_SITE\"))\n",
    "print(\"DD_SERVICE:\", os.getenv(\"DD_SERVICE\"))\n",
    "print(\"DD_ENV:\", os.getenv(\"DD_ENV\"))\n",
    "print(\"DD_VERSION:\", os.getenv(\"DD_VERSION\"))\n",
    "print(\"DD_TRACE_AGENT_URL:\", os.getenv(\"DD_TRACE_AGENT_URL\"))\n",
    "print(\"DD_TRACE_AGENT_PORT:\", os.getenv(\"DD_TRACE_AGENT_PORT\"))\n",
    "\n",
    "print(\"OTEL_EXPORTER_OTLP_TRACES_PROTOCOL:\", os.getenv(\"OTEL_EXPORTER_OTLP_TRACES_PROTOCOL\"))\n",
    "print(\"OTEL_EXPORTER_OTLP_TRACES_ENDPOINT:\", os.getenv(\"OTEL_EXPORTER_OTLP_TRACES_ENDPOINT\"))\n",
    "print(\"OTEL_EXPORTER_OTLP_TRACES_HEADERS:\", os.getenv(\"OTEL_EXPORTER_OTLP_TRACES_HEADERS\"))\n",
    "print(\"OTEL_SERVICE_NAME:\", os.getenv(\"OTEL_SERVICE_NAME\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "191ddb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddtrace.llmobs import LLMObs\n",
    "LLMObs.enable(\n",
    "  ml_app=os.getenv(\"DD_LLMOBS_ML_APP\"),\n",
    "  api_key=os.getenv(\"DD_API_KEY\"),\n",
    "  service=os.getenv(\"DD_SERVICE\"),\n",
    "  agentless_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e20708d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# --- 1. Helper Function: Group and Sort Images ---\n",
    "def get_district_image_groups(directory, district_name):\n",
    "    \"\"\"\n",
    "    Scans a directory for image files matching a specific district name,\n",
    "    groups them by their report ID, and sorts them by page number.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The path to the directory containing image files.\n",
    "        district_name (str): The name of the district to filter by (e.g., \"Bang Phlat\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are report IDs (e.g., \"BangPhlat25\")\n",
    "              and values are lists of sorted file paths.\n",
    "              Example: { \"BangPhlat25\": [\"path/to/p1.jpg\", \"path/to/p2.jpg\"] }\n",
    "    \"\"\"\n",
    "    grouped_images = {}\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Error: Directory '{directory}' not found.\")\n",
    "        return {}\n",
    "\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    for filename in files:\n",
    "        # Filter for image files and the specific district name\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')) and district_name in filename:\n",
    "            \n",
    "            # Logic to extract Report ID:\n",
    "            # Assuming filename format like \"District25_page1.jpg\",\n",
    "            # we split by \"_page\" to get \"District25\" as the group key.\n",
    "            if \"_page\" in filename:\n",
    "                report_id = filename.split(\"_page\")[0]\n",
    "                \n",
    "                if report_id not in grouped_images:\n",
    "                    grouped_images[report_id] = []\n",
    "                \n",
    "                full_path = os.path.join(directory, filename)\n",
    "                grouped_images[report_id].append(full_path)\n",
    "\n",
    "    # Sort images within each group based on the page number in the filename\n",
    "    for report_id in grouped_images:\n",
    "        # Use regex to find '_pageX' and extract the integer X for sorting\n",
    "        grouped_images[report_id].sort(\n",
    "            key=lambda x: int(re.search(r'_page(\\d+)', x).group(1)) if re.search(r'_page(\\d+)', x) else 0\n",
    "        )\n",
    "        \n",
    "    return grouped_images\n",
    "\n",
    "# --- 2. Gemini Function: Multi-page Extraction ---\n",
    "def extract_from_multipage_report(image_paths, client):\n",
    "    \"\"\"\n",
    "    Sends multiple document pages to Gemini for extraction, following best practices:\n",
    "    1. Indexes each image (e.g., \"Page 1\").\n",
    "    2. Places all images BEFORE the main text prompt.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): A list of file paths to the images (sorted).\n",
    "        client (genai.Client): The initialized Google Gen AI client.\n",
    "\n",
    "    Returns:\n",
    "        dict: The extracted data as a JSON object, or None if extraction fails.\n",
    "    \"\"\"\n",
    "    \n",
    "    # List to hold all content parts (Text labels + Image bytes)\n",
    "    content_parts = []\n",
    "    \n",
    "    # A. Process Images (Loop through sorted paths)\n",
    "    for i, path in enumerate(image_paths, 1):\n",
    "        try:\n",
    "            filename = os.path.basename(path)\n",
    "            \n",
    "            # 1. Best Practice: Add an Index Label BEFORE the image.\n",
    "            # This helps the model identify which page contains specific data (e.g., header vs table).\n",
    "            index_label = f\"Page {i} (Filename: {filename})\"\n",
    "            content_parts.append(index_label) \n",
    "            \n",
    "            # 2. Read image bytes\n",
    "            with open(path, \"rb\") as f:\n",
    "                image_bytes = f.read()\n",
    "            \n",
    "            # 3. Create a Part object with the correct MIME type\n",
    "            # Note: Ensure the MIME type matches your actual files (image/jpeg or image/png)\n",
    "            image_part = types.Part.from_bytes(\n",
    "                data=image_bytes,\n",
    "                mime_type=\"image/jpeg\" \n",
    "            )\n",
    "            content_parts.append(image_part)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # B. Main Text Prompt (Placed AFTER all images)\n",
    "    # This instructs the model to synthesize information from the indexed images above.\n",
    "    prompt_text = \"\"\"\n",
    "    You are an expert data entry assistant for Thai Election documents (Form S.S. 5/18).\n",
    "    \n",
    "    Instructions:\n",
    "    1. Analyze the sequence of images labeled Page 1, Page 2, etc. provided above. These pages belong to the SAME single report.\n",
    "    2. Extract information strictly according to the JSON schema provided.\n",
    "    3. Consolidate data from all pages. \n",
    "       - The header information (District, Date) is usually on Page 1.\n",
    "       - The 'Vote Results' table often spans across multiple pages. Merge them into a single list.\n",
    "    4. Validation: Ensure the 'total ballots used' matches the sum of 'good', 'bad', and 'no vote' ballots.\n",
    "    5. Form Type: Detect if this is a 'Constituency' form (candidates with names) or 'PartyList' form (party names only).\n",
    "    \"\"\"\n",
    "    content_parts.append(prompt_text)\n",
    "\n",
    "    # C. Send Request to Gemini\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\", \n",
    "            contents=content_parts,   # List structure: [Index, Img, Index, Img, ..., Main Prompt]\n",
    "            config=types.GenerateContentConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=election_form_schema,\n",
    "                temperature=0.0, # Low temperature for factual extraction\n",
    "            ),\n",
    "        )\n",
    "        return json.loads(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Gemini: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 3. Schema Definition ---\n",
    "election_form_schema = {\n",
    "    \"type\": \"OBJECT\",\n",
    "    \"properties\": {\n",
    "        \"form_info\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"description\": \"Header information identifying the polling station.\",\n",
    "            \"properties\": {\n",
    "                \"date\": {\"type\": \"STRING\", \"description\": \"Date of election (e.g., 14 May 2566)\"},\n",
    "                \"province\": {\"type\": \"STRING\", \"description\": \"Province name\"},\n",
    "                \"district\": {\"type\": \"STRING\", \"description\": \"District name (Amphoe/Khet)\"},\n",
    "                \"constituency_number\": {\"type\": \"STRING\", \"description\": \"Constituency number\"},\n",
    "                \"polling_station_number\": {\"type\": \"STRING\", \"description\": \"Unit/Polling Station number\"},\n",
    "                \"form_type\": {\n",
    "                    \"type\": \"STRING\",\n",
    "                    \"enum\": [\"Constituency\", \"PartyList\"],\n",
    "                    \"description\": \"Type of form: Constituency (Candidates) or PartyList (Parties)\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"province\", \"district\", \"polling_station_number\"]\n",
    "        },\n",
    "        \"ballot_statistics\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"description\": \"Section 2: Ballot accounting statistics.\",\n",
    "            \"properties\": {\n",
    "                \"ballots_used\": {\"type\": \"INTEGER\", \"description\": \"Item 2.2: Total used ballots\"},\n",
    "                \"good_ballots\": {\"type\": \"INTEGER\", \"description\": \"Item 2.2.1: Valid ballots\"},\n",
    "                \"bad_ballots\": {\"type\": \"INTEGER\", \"description\": \"Item 2.2.2: Void/Spoiled ballots\"},\n",
    "                \"no_vote_ballots\": {\"type\": \"INTEGER\", \"description\": \"Item 2.2.3: No Vote ballots\"}\n",
    "            }\n",
    "        },\n",
    "        \"vote_results\": {\n",
    "            \"type\": \"ARRAY\",\n",
    "            \"description\": \"Section 3: Vote counts table. Extract all rows from all pages.\",\n",
    "            \"items\": {\n",
    "                \"type\": \"OBJECT\",\n",
    "                \"properties\": {\n",
    "                    \"number\": {\"type\": \"INTEGER\", \"description\": \"Candidate/Party Number\"},\n",
    "                    \"name\": {\"type\": \"STRING\", \"description\": \"Candidate Name or Party Name\"},\n",
    "                    \"vote_count\": {\"type\": \"INTEGER\", \"description\": \"Vote count (numeric)\"},\n",
    "                    \"vote_count_text\": {\"type\": \"STRING\", \"description\": \"Vote count (Thai written text)\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"form_info\", \"ballot_statistics\", \"vote_results\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55aa5da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: assets/ss5-18/ss5-18-images/ for district: บางพลัด25...\n",
      "--------------------------------------------------\n",
      "Processing Report ID: บางพลัด25\n",
      "Found 6 pages: ['บางพลัด25_page1.jpg', 'บางพลัด25_page2.jpg', 'บางพลัด25_page3.jpg', 'บางพลัด25_page4.jpg', 'บางพลัด25_page5.jpg', 'บางพลัด25_page6.jpg']\n",
      "Extraction Success!\n",
      "{\n",
      "  \"form_info\": {\n",
      "    \"date\": \"14 พฤษภาคม 2566\",\n",
      "    \"province\": \"กรุงเทพมหานคร\",\n",
      "    \"district\": \"บางพลัด\",\n",
      "    \"constituency_number\": \"25\",\n",
      "    \"polling_station_number\": \"25\",\n",
      "    \"form_type\": \"Constituency\"\n",
      "  },\n",
      "  \"ballot_statistics\": {\n",
      "    \"ballots_used\": 433,\n",
      "    \"good_ballots\": 415,\n",
      "    \"bad_ballots\": 6,\n",
      "    \"no_vote_ballots\": 12\n",
      "  },\n",
      "  \"vote_results\": [\n",
      "    {\n",
      "      \"number\": 1,\n",
      "      \"name\": \"นายจักรพันธ์ พรหมิภร\",\n",
      "      \"vote_count\": 17,\n",
      "      \"vote_count_text\": \"สิบเจ็ด\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 2,\n",
      "      \"name\": \"นายกฤษณ์ สุริยผล\",\n",
      "      \"vote_count\": 2,\n",
      "      \"vote_count_text\": \"สอง\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 3,\n",
      "      \"name\": \"นางทัศวรรณ รุจิชัย\",\n",
      "      \"vote_count\": 1,\n",
      "      \"vote_count_text\": \"หนึ่ง\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 4,\n",
      "      \"name\": \"นายปรีชร แสงกิตติกร\",\n",
      "      \"vote_count\": 0,\n",
      "      \"vote_count_text\": \"ศูนย์\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 5,\n",
      "      \"name\": \"นางรัตถา อินทวงศ์ สุวรรณศรี\",\n",
      "      \"vote_count\": 110,\n",
      "      \"vote_count_text\": \"หนึ่งร้อยสิบ\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 6,\n",
      "      \"name\": \"นายพงศ์พันธ์ ยอดเมืองเจริญ\",\n",
      "      \"vote_count\": 188,\n",
      "      \"vote_count_text\": \"หนึ่งร้อยแปดสิบแปด\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 7,\n",
      "      \"name\": \"นายชนินทร์ รุ่งแสง\",\n",
      "      \"vote_count\": 26,\n",
      "      \"vote_count_text\": \"ยี่สิบหก\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 8,\n",
      "      \"name\": \"นางสาวรัชนก ศรีทองแท้\",\n",
      "      \"vote_count\": 0,\n",
      "      \"vote_count_text\": \"ศูนย์\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 9,\n",
      "      \"name\": \"ว่าที่ร้อยตรี สานนท์ บุญมี\",\n",
      "      \"vote_count\": 3,\n",
      "      \"vote_count_text\": \"สาม\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 10,\n",
      "      \"name\": \"นางสาวพิมพนาท พึ่งรุ่งเรืองวัฒนา\",\n",
      "      \"vote_count\": 1,\n",
      "      \"vote_count_text\": \"หนึ่ง\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 11,\n",
      "      \"name\": \"นางสาวนันทิกา ครองสินทรัพย์\",\n",
      "      \"vote_count\": 3,\n",
      "      \"vote_count_text\": \"สาม\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 12,\n",
      "      \"name\": \"นายณัฐวัฒน์ พอใช้ได้\",\n",
      "      \"vote_count\": 1,\n",
      "      \"vote_count_text\": \"หนึ่ง\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 13,\n",
      "      \"name\": \"นายธิติรัฐ อดิศรพันธ์กุล\",\n",
      "      \"vote_count\": 57,\n",
      "      \"vote_count_text\": \"ห้าสิบเจ็ด\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 14,\n",
      "      \"name\": \"นายกภพ เปลี่ยนจินดา\",\n",
      "      \"vote_count\": 0,\n",
      "      \"vote_count_text\": \"ศูนย์\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 15,\n",
      "      \"name\": \"นายคมสัน พันธุ์ชาติกุล\",\n",
      "      \"vote_count\": 4,\n",
      "      \"vote_count_text\": \"สี่\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": 16,\n",
      "      \"name\": \"ว่าที่ร้อยเอก บรรพต ครองผล\",\n",
      "      \"vote_count\": 2,\n",
      "      \"vote_count_text\": \"สอง\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "failed to send, dropping 1 traces to intake at http://localhost:8126/v0.5/traces: client error (Connect)\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Main Execution Block ---\n",
    "# Configuration\n",
    "# Ensure this path points to your actual image directory\n",
    "IMAGE_DIR = \"assets/ss5-18/ss5-18-images/\"\n",
    "DISTRICT_NAME = \"บางพลัด25\" # District name to filter by (can be part of the filename)\n",
    "\n",
    "# Initialize the Gemini Client (Credentials are auto-detected from env vars)\n",
    "client = genai.Client()\n",
    "\n",
    "print(f\"Scanning directory: {IMAGE_DIR} for district: {DISTRICT_NAME}...\")\n",
    "\n",
    "# Get images grouped by Report ID and sorted by page\n",
    "report_groups = get_district_image_groups(IMAGE_DIR, DISTRICT_NAME)\n",
    "\n",
    "if not report_groups:\n",
    "    print(\"No images found matching the criteria.\")\n",
    "else:\n",
    "    # Iterate through each report group (e.g., Report \"BangPhlat25\" with 6 pages)\n",
    "    for report_id, pages in report_groups.items():\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Processing Report ID: {report_id}\")\n",
    "        print(f\"Found {len(pages)} pages: {[os.path.basename(p) for p in pages]}\")\n",
    "        \n",
    "        # Extract data from the multi-page document\n",
    "        result = extract_from_multipage_report(pages, client)\n",
    "        \n",
    "        if result:\n",
    "            print(\"Extraction Success!\")\n",
    "            # Print the result nicely formatted\n",
    "            print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "        else:\n",
    "            print(\"Failed to extract data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3da7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
