services:
  fastapi-backend:
    build:
      context: ./services/fastapi-backend
      dockerfile: Dockerfile
      args:
        - DD_GIT_REPOSITORY_URL=${DD_GIT_REPOSITORY_URL:-https://github.com/nuttea/genai-app-python.git}
        - DD_GIT_COMMIT_SHA=${DD_GIT_COMMIT_SHA:-unknown}
    container_name: genai-fastapi-backend
    ports:
      - "8000:8000"
    # Override entrypoint for local development (Cloud Run uses datadog-init)
    entrypoint: []
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
    environment:
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT}
      - VERTEX_AI_LOCATION=${VERTEX_AI_LOCATION:-us-central1}
      - FASTAPI_ENV=${FASTAPI_ENV:-development}
      - FASTAPI_HOST=0.0.0.0
      - FASTAPI_PORT=8000
      - LOG_LEVEL=${LOG_LEVEL:-debug}
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:3000,http://localhost:8000,http://localhost:8501,http://localhost:8002}
      - DEFAULT_MODEL=${DEFAULT_MODEL:-gemini-pro}
      - DEFAULT_TEMPERATURE=${DEFAULT_TEMPERATURE:-0.7}
      - DEFAULT_MAX_TOKENS=${DEFAULT_MAX_TOKENS:-1024}
      - DEBUG=${DEBUG:-false}
      - RELOAD=${RELOAD:-true}
      # API Key Configuration
      - API_KEY=${API_KEY:-}
      - API_KEY_REQUIRED=${API_KEY_REQUIRED:-false}
      # Google AI API Configuration (for dynamic model listing)
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      # Datadog APM and LLM Observability (optional)
      - DD_API_KEY=${DD_API_KEY:-}
      - DD_SITE=${DD_SITE:-datadoghq.com}
      - DD_SERVICE=${DD_SERVICE:-genai-fastapi-backend}
      - DD_ENV=${DD_ENV:-development}
      - DD_VERSION=${DD_VERSION:-0.1.0}
      - DD_LOGS_ENABLED=true
      - DD_LOGS_INJECTION=true
      - DD_SOURCE=python
      - DD_TRACE_SAMPLE_RATE=${DD_TRACE_SAMPLE_RATE:-1.0}
      - DD_LLMOBS_ML_APP=${DD_LLMOBS_ML_APP:-}
      - DD_LLMOBS_ENABLED=${DD_LLMOBS_ENABLED:-0}
      # Datadog Trace Agent Configuration
      - DD_TRACE_AGENT_URL=${DD_TRACE_AGENT_URL:-http://localhost:8136}
      - DD_AGENT_HOST=${DD_AGENT_HOST:-localhost}
      - DD_TRACE_AGENT_PORT=${DD_TRACE_AGENT_PORT:-8136}
      - DD_TRACE_ENABLED=${DD_TRACE_ENABLED:-1}
      - DD_CODE_ORIGIN_FOR_SPANS_ENABLED=${DD_CODE_ORIGIN_FOR_SPANS_ENABLED:-true}
    volumes:
      # Mount gcloud application default credentials for authentication
      - ${HOME}/.config/gcloud:/root/.config/gcloud:ro
      # Mount code for development (hot reload)
      - ./services/fastapi-backend/app:/app/app:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - genai-network

  # MCP Server (Future)
  # mcp-server:
  #   build:
  #     context: ./services/mcp-server
  #     dockerfile: Dockerfile
  #   container_name: genai-mcp-server
  #   ports:
  #     - "3001:3001"
  #   environment:
  #     - NODE_ENV=development
  #   networks:
  #     - genai-network

  # Streamlit Frontend
  streamlit-frontend:
    build:
      context: ./frontend/streamlit
      dockerfile: Dockerfile
      args:
        - DD_GIT_REPOSITORY_URL=${DD_GIT_REPOSITORY_URL:-https://github.com/nuttea/genai-app-python.git}
        - DD_GIT_COMMIT_SHA=${DD_GIT_COMMIT_SHA:-unknown}
    container_name: genai-streamlit-frontend
    ports:
      - "8501:8501"
    # Override entrypoint for local development (Cloud Run uses datadog-init)
    entrypoint: []
    command: ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
    environment:
      - API_BASE_URL=http://fastapi-backend:8000
      - FASTAPI_ENV=${FASTAPI_ENV:-development}
      - API_KEY=${API_KEY:-}
      # Datadog (optional, but tracing disabled for local dev without serverless-init)
      - DD_API_KEY=${DD_API_KEY:-}
      - DD_SITE=${DD_SITE:-datadoghq.com}
      - DD_SERVICE=${DD_SERVICE:-genai-streamlit-frontend}
      - DD_ENV=${DD_ENV:-development}
      - DD_VERSION=${DD_VERSION:-0.1.0}
      - DD_TRACE_ENABLED=${DD_TRACE_ENABLED:-0}
      - DD_CODE_ORIGIN_FOR_SPANS_ENABLED=${DD_CODE_ORIGIN_FOR_SPANS_ENABLED:-true}
      # Datadog Trace Agent Configuration
      - DD_TRACE_AGENT_URL=${DD_TRACE_AGENT_URL:-http://localhost:8136}
      - DD_AGENT_HOST=${DD_AGENT_HOST:-localhost}
      - DD_TRACE_AGENT_PORT=${DD_TRACE_AGENT_PORT:-8136}
      # Datadog RUM (Real User Monitoring)
      - DD_RUM_CLIENT_TOKEN=${DD_RUM_CLIENT_TOKEN:-}
      - DD_RUM_APPLICATION_ID=${DD_RUM_APPLICATION_ID:-}
    volumes:
      # Mount code for development (hot reload)
      - ./frontend/streamlit:/app:ro
    depends_on:
      fastapi-backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - genai-network

  # ADK Python Service - Multi-Agent Content Creation
  adk-python:
    build:
      context: ./services/adk-python
      dockerfile: Dockerfile
    container_name: genai-adk-python
    ports:
      - "8002:8002"
    command:
      [
        "hypercorn",
        "main_adk:app",
        "--bind",
        "0.0.0.0:8002",
        "--reload",
        "--worker-class",
        "asyncio",
      ]
    environment:
      # Google Cloud & ADK Configuration
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT}
      - GOOGLE_CLOUD_LOCATION=${GOOGLE_CLOUD_LOCATION:-global}
      - GOOGLE_GENAI_USE_VERTEXAI=${GOOGLE_GENAI_USE_VERTEXAI:-True}
      - VERTEX_AI_LOCATION=${VERTEX_AI_LOCATION:-us-central1}
      - CLOUD_STORAGE_BUCKET=${CLOUD_STORAGE_BUCKET:-content-uploads}
      - PORT=8002
      - DEBUG=${DEBUG:-true}
      - ENVIRONMENT=${ENVIRONMENT:-development}
      # LLM Configuration
      - DEFAULT_MODEL=${DEFAULT_MODEL:-gemini-2.5-flash}
      - DEFAULT_TEMPERATURE=0.7
      - DEFAULT_MAX_TOKENS=8192
      # Video Processing
      - VIDEO_FRAME_INTERVAL=2
      - MAX_VIDEO_DURATION=600
      # Content Configuration
      - DEFAULT_BLOG_LENGTH=medium
      - DEFAULT_TONE=professional
      - DEFAULT_AUDIENCE=developers
      # API Key (optional)
      - API_KEY=${API_KEY:-}
      # Datadog Configuration (optional)
      - DD_API_KEY=${DD_API_KEY:-}
      - DD_SITE=${DD_SITE:-datadoghq.com}
      - DD_SERVICE=adk-python
      - DD_ENV=${DD_ENV:-development}
      - DD_VERSION=0.1.0
      - DD_TRACE_ENABLED=${DD_TRACE_ENABLED:-1}
      - DD_CODE_ORIGIN_FOR_SPANS_ENABLED=${DD_CODE_ORIGIN_FOR_SPANS_ENABLED:-true}
      # Datadog Trace Agent Configuration
      - DD_TRACE_AGENT_URL=${DD_TRACE_AGENT_URL:-http://localhost:8136}
      - DD_AGENT_HOST=${DD_AGENT_HOST:-localhost}
      - DD_TRACE_AGENT_PORT=${DD_TRACE_AGENT_PORT:-8136}
    volumes:
      # Mount gcloud application default credentials
      - ${HOME}/.config/gcloud:/root/.config/gcloud:ro
      # Mount code for development (hot reload)
      - ./services/adk-python/app:/app/app:ro
      - ./services/adk-python/content_creator_agent:/app/content_creator_agent:ro
      # Mount uploads directory
      - ./services/adk-python/uploads:/app/uploads
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - genai-network

  # Next.js Frontend - Modern UI for GenAI Services
  nextjs-frontend:
    build:
      context: ./frontend/nextjs
      dockerfile: Dockerfile
    container_name: genai-nextjs-frontend
    ports:
      - "3000:3000"
    environment:
      # Application Info
      - NEXT_PUBLIC_APP_NAME=Datadog GenAI Platform
      - NEXT_PUBLIC_APP_VERSION=1.0.0
      # API URLs (Client-side - publicly accessible)
      - NEXT_PUBLIC_VOTE_EXTRACTOR_API=http://localhost:8000
      - NEXT_PUBLIC_CONTENT_CREATOR_API=http://localhost:8002
      # API URLs (Server-side - internal routing)
      - VOTE_EXTRACTOR_API_URL=http://fastapi-backend:8000
      - CONTENT_CREATOR_API_URL=http://adk-python:8002
      # Datadog RUM (optional)
      - NEXT_PUBLIC_DD_APPLICATION_ID=${DD_RUM_APPLICATION_ID:-}
      - NEXT_PUBLIC_DD_CLIENT_TOKEN=${DD_RUM_CLIENT_TOKEN:-}
      - NEXT_PUBLIC_DD_SITE=${DD_SITE:-datadoghq.com}
      - NEXT_PUBLIC_DD_SERVICE=nextjs-frontend
      - NEXT_PUBLIC_DD_ENV=${DD_ENV:-development}
      - NEXT_PUBLIC_DD_VERSION=1.0.0
      - NEXT_PUBLIC_DD_SESSION_REPLAY_ENABLED=true
      - NEXT_PUBLIC_DD_SESSION_SAMPLE_RATE=100
      - NEXT_PUBLIC_DD_TRACE_ENABLED=true
      - NEXT_PUBLIC_DD_TRACE_SAMPLE_RATE=100
      # Node Environment
      - NODE_ENV=development
      # API Key (optional) - Must be NEXT_PUBLIC_ prefix for browser access
      - NEXT_PUBLIC_API_KEY=${API_KEY:-}
    volumes:
      # Mount code for development (hot reload)
      # Note: Removed :ro to allow Next.js to write .next build directory
      - ./frontend/nextjs:/app
      # Exclude node_modules from mount (use container's version)
      - nextjs-node-modules:/app/node_modules
      # Exclude .next from mount (build artifacts)
      - nextjs-build:/app/.next
    depends_on:
      fastapi-backend:
        condition: service_healthy
      adk-python:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000', (r) => {if (r.statusCode !== 200) throw new Error(r.statusCode)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - genai-network

networks:
  genai-network:
    driver: bridge

volumes:
  nextjs-node-modules:
    driver: local
  nextjs-build:
    driver: local
