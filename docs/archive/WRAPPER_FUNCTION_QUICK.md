# ğŸš€ Wrapper Function - Quick Reference

**Function**: `run_model_experiments()`  
**Location**: `notebooks/datasets/01_prepare_vote_extraction_dataset.ipynb` â†’ Section 6  
**Status**: âœ… Ready to use

---

## ğŸ’¡ What It Does

Runs multiple LLM experiments with different models/temperatures in a single function call.

**Features**:
- âœ… Automatic LLMObs initialization
- âœ… Multiple model configurations
- âœ… Temperature comparisons
- âœ… Parallel processing
- âœ… Automatic comparison table
- âœ… Best performer identification

---

## ğŸš€ Quick Start

### Simplest Usage (3 Default Models)

```python
results = run_model_experiments(
    sample_size=10,
    jobs=2,
    raise_errors=True
)
```

**Runs**: gemini-2.5-flash, flash-lite, 3-pro-preview (all at T=0.0)

---

## ğŸ“‹ Common Patterns

### Pattern 1: Temperature Comparison

```python
results = run_model_experiments(
    model_configs=[
        {"model": "gemini-2.5-flash", "temperature": 0.0},
        {"model": "gemini-2.5-flash", "temperature": 0.1},
        {"model": "gemini-2.5-flash", "temperature": 0.2}
    ],
    sample_size=10,
    jobs=2
)
```

### Pattern 2: Cost vs. Quality

```python
results = run_model_experiments(
    model_configs=[
        {"model": "gemini-2.5-flash-lite", "temperature": 0.0},  # Low cost
        {"model": "gemini-2.5-flash", "temperature": 0.0},       # Medium
        {"model": "gemini-3-pro-preview", "temperature": 0.0}    # High cost
    ]
)
```

### Pattern 3: Fast Iteration

```python
# Quick test on 3 records
results = run_model_experiments(
    model_configs=[
        {"model": "gemini-2.5-flash", "temperature": 0.0}
    ],
    sample_size=3,
    jobs=1
)
```

---

## âš™ï¸ Key Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `model_configs` | 3 models | List of models to test |
| `sample_size` | All | Number of records (None = all) |
| `jobs` | `2` | Parallel processing |
| `raise_errors` | `True` | Stop on first error |
| `show_comparison` | `True` | Print comparison table |

---

## ğŸ“Š Output

```
ğŸ”§ INITIALIZING DATADOG LLMOBS
âœ… LLMObs enabled

ğŸ“Š Loading dataset: vote-extraction-bangbamru-1-10
âœ… Dataset loaded: 10 records

ğŸš€ RUNNING 3 EXPERIMENTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ§ª Experiment 1/3: gemini-2.5-flash (T=0.0)
âœ… Created: vote-extraction-flash-t0
â±ï¸  Running...
âœ… Completed! Processed 10 records
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“Š EXPERIMENT COMPARISON
Experiment              Model                 Temp  Accuracy  Success
vote-extraction-flash   gemini-2.5-flash     0.0   98.5%     100%
vote-extraction-lite    flash-lite           0.0   96.8%     100%
vote-extraction-pro     3-pro-preview        0.0   99.1%     100%

ğŸ” Compare all experiments side-by-side:
   https://app.datadoghq.com/llm/experiments?dataset=241bfded...&project=vote-extraction-project

ğŸ† BEST PERFORMER:
   Model: gemini-3-pro-preview
   Temperature: 0.0
   Overall Accuracy: 99.1%
```

---

## ğŸ“¤ Return Value

```python
{
    "experiments": [
        {
            "experiment_name": "vote-extraction-flash-t0",
            "model": "gemini-2.5-flash",
            "temperature": 0.0,
            "summary_metrics": {"overall_accuracy": 98.5, ...},
            "url": "https://app.datadoghq.com/...",
            "status": "success"
        },
        ...
    ],
    "total_experiments": 3,
    "successful_experiments": 3,
    "failed_experiments": 0,
    "comparison_url": "https://app.datadoghq.com/llm/experiments?dataset=...&project=...",
    "dataset_id": "241bfded-e79d-4d2d-bbc4-a74bb06d85f9"
}
```

---

## ğŸ’¡ Pro Tips

### 1. Start Small
```python
# Test with sample first
results = run_model_experiments(sample_size=3)

# Then run full dataset
results = run_model_experiments(sample_size=None)
```

### 2. Custom Naming
```python
model_configs=[
    {
        "model": "gemini-2.5-flash",
        "temperature": 0.0,
        "name_suffix": "prod-v1-baseline"  # Custom name
    }
]
```

### 3. Continue on Errors
```python
# Don't stop if one fails
results = run_model_experiments(
    raise_errors=False
)
```

### 4. Use Comparison URL
```python
results = run_model_experiments(...)

# Open in browser for side-by-side comparison
import webbrowser
if 'comparison_url' in results:
    webbrowser.open(results['comparison_url'])
```

---

## ğŸ†˜ Troubleshooting

| Issue | Solution |
|-------|----------|
| "DD_API_KEY not found" | Set in `.env` or pass as parameter |
| "Dataset not found" | Check `dataset_name` parameter |
| Experiment fails | Check `raise_errors` setting |
| Slow execution | Reduce `sample_size` or increase `jobs` |

---

## ğŸ“š Full Documentation

See [WRAPPER_FUNCTION_COMPLETE.md](WRAPPER_FUNCTION_COMPLETE.md) for:
- Complete parameter reference
- Advanced examples
- Error handling
- Best practices

---

**Ready!** ğŸ‰ Open the notebook and call `run_model_experiments()`!

